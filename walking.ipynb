{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Deep learning with Keras</center></h1>\n",
    "\n",
    "<center>Owen Jones | Bath ML | 3rd June 2018</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start at the very beginning..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK yes, that is not the most interesting beginning. But it means that the results in this notebook are now reproducible (yay!). Good. Moving on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Keras?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. -- **[keras.io](https://keras.io)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, Keras makes it super easy to build neural networks. And that is exactly what we're going to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jones\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The best dataset in the world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the hang of the Keras syntax, we're going to start off with a really simple network on a really simple dataset. You might have come across this one before...\n",
    "\n",
    "We're going to be using a little bit of `numpy`, because Keras works with data stored in `numpy` arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2, 0. ],\n",
       "       [4.9, 3. , 1.4, 0.2, 0. ],\n",
       "       [4.7, 3.2, 1.3, 0.2, 0. ],\n",
       "       [4.6, 3.1, 1.5, 0.2, 0. ],\n",
       "       [5. , 3.6, 1.4, 0.2, 0. ],\n",
       "       [5.4, 3.9, 1.7, 0.4, 0. ],\n",
       "       [4.6, 3.4, 1.4, 0.3, 0. ],\n",
       "       [5. , 3.4, 1.5, 0.2, 0. ],\n",
       "       [4.4, 2.9, 1.4, 0.2, 0. ],\n",
       "       [4.9, 3.1, 1.5, 0.1, 0. ],\n",
       "       [5.4, 3.7, 1.5, 0.2, 0. ],\n",
       "       [4.8, 3.4, 1.6, 0.2, 0. ],\n",
       "       [4.8, 3. , 1.4, 0.1, 0. ],\n",
       "       [4.3, 3. , 1.1, 0.1, 0. ],\n",
       "       [5.8, 4. , 1.2, 0.2, 0. ],\n",
       "       [5.7, 4.4, 1.5, 0.4, 0. ],\n",
       "       [5.4, 3.9, 1.3, 0.4, 0. ],\n",
       "       [5.1, 3.5, 1.4, 0.3, 0. ],\n",
       "       [5.7, 3.8, 1.7, 0.3, 0. ],\n",
       "       [5.1, 3.8, 1.5, 0.3, 0. ],\n",
       "       [5.4, 3.4, 1.7, 0.2, 0. ],\n",
       "       [5.1, 3.7, 1.5, 0.4, 0. ],\n",
       "       [4.6, 3.6, 1. , 0.2, 0. ],\n",
       "       [5.1, 3.3, 1.7, 0.5, 0. ],\n",
       "       [4.8, 3.4, 1.9, 0.2, 0. ],\n",
       "       [5. , 3. , 1.6, 0.2, 0. ],\n",
       "       [5. , 3.4, 1.6, 0.4, 0. ],\n",
       "       [5.2, 3.5, 1.5, 0.2, 0. ],\n",
       "       [5.2, 3.4, 1.4, 0.2, 0. ],\n",
       "       [4.7, 3.2, 1.6, 0.2, 0. ],\n",
       "       [4.8, 3.1, 1.6, 0.2, 0. ],\n",
       "       [5.4, 3.4, 1.5, 0.4, 0. ],\n",
       "       [5.2, 4.1, 1.5, 0.1, 0. ],\n",
       "       [5.5, 4.2, 1.4, 0.2, 0. ],\n",
       "       [4.9, 3.1, 1.5, 0.1, 0. ],\n",
       "       [5. , 3.2, 1.2, 0.2, 0. ],\n",
       "       [5.5, 3.5, 1.3, 0.2, 0. ],\n",
       "       [4.9, 3.1, 1.5, 0.1, 0. ],\n",
       "       [4.4, 3. , 1.3, 0.2, 0. ],\n",
       "       [5.1, 3.4, 1.5, 0.2, 0. ],\n",
       "       [5. , 3.5, 1.3, 0.3, 0. ],\n",
       "       [4.5, 2.3, 1.3, 0.3, 0. ],\n",
       "       [4.4, 3.2, 1.3, 0.2, 0. ],\n",
       "       [5. , 3.5, 1.6, 0.6, 0. ],\n",
       "       [5.1, 3.8, 1.9, 0.4, 0. ],\n",
       "       [4.8, 3. , 1.4, 0.3, 0. ],\n",
       "       [5.1, 3.8, 1.6, 0.2, 0. ],\n",
       "       [4.6, 3.2, 1.4, 0.2, 0. ],\n",
       "       [5.3, 3.7, 1.5, 0.2, 0. ],\n",
       "       [5. , 3.3, 1.4, 0.2, 0. ],\n",
       "       [7. , 3.2, 4.7, 1.4, 1. ],\n",
       "       [6.4, 3.2, 4.5, 1.5, 1. ],\n",
       "       [6.9, 3.1, 4.9, 1.5, 1. ],\n",
       "       [5.5, 2.3, 4. , 1.3, 1. ],\n",
       "       [6.5, 2.8, 4.6, 1.5, 1. ],\n",
       "       [5.7, 2.8, 4.5, 1.3, 1. ],\n",
       "       [6.3, 3.3, 4.7, 1.6, 1. ],\n",
       "       [4.9, 2.4, 3.3, 1. , 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3, 1. ],\n",
       "       [5.2, 2.7, 3.9, 1.4, 1. ],\n",
       "       [5. , 2. , 3.5, 1. , 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5, 1. ],\n",
       "       [6. , 2.2, 4. , 1. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4, 1. ],\n",
       "       [5.6, 2.9, 3.6, 1.3, 1. ],\n",
       "       [6.7, 3.1, 4.4, 1.4, 1. ],\n",
       "       [5.6, 3. , 4.5, 1.5, 1. ],\n",
       "       [5.8, 2.7, 4.1, 1. , 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5, 1. ],\n",
       "       [5.6, 2.5, 3.9, 1.1, 1. ],\n",
       "       [5.9, 3.2, 4.8, 1.8, 1. ],\n",
       "       [6.1, 2.8, 4. , 1.3, 1. ],\n",
       "       [6.3, 2.5, 4.9, 1.5, 1. ],\n",
       "       [6.1, 2.8, 4.7, 1.2, 1. ],\n",
       "       [6.4, 2.9, 4.3, 1.3, 1. ],\n",
       "       [6.6, 3. , 4.4, 1.4, 1. ],\n",
       "       [6.8, 2.8, 4.8, 1.4, 1. ],\n",
       "       [6.7, 3. , 5. , 1.7, 1. ],\n",
       "       [6. , 2.9, 4.5, 1.5, 1. ],\n",
       "       [5.7, 2.6, 3.5, 1. , 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1, 1. ],\n",
       "       [5.5, 2.4, 3.7, 1. , 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2, 1. ],\n",
       "       [6. , 2.7, 5.1, 1.6, 1. ],\n",
       "       [5.4, 3. , 4.5, 1.5, 1. ],\n",
       "       [6. , 3.4, 4.5, 1.6, 1. ],\n",
       "       [6.7, 3.1, 4.7, 1.5, 1. ],\n",
       "       [6.3, 2.3, 4.4, 1.3, 1. ],\n",
       "       [5.6, 3. , 4.1, 1.3, 1. ],\n",
       "       [5.5, 2.5, 4. , 1.3, 1. ],\n",
       "       [5.5, 2.6, 4.4, 1.2, 1. ],\n",
       "       [6.1, 3. , 4.6, 1.4, 1. ],\n",
       "       [5.8, 2.6, 4. , 1.2, 1. ],\n",
       "       [5. , 2.3, 3.3, 1. , 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3, 1. ],\n",
       "       [5.7, 3. , 4.2, 1.2, 1. ],\n",
       "       [5.7, 2.9, 4.2, 1.3, 1. ],\n",
       "       [6.2, 2.9, 4.3, 1.3, 1. ],\n",
       "       [5.1, 2.5, 3. , 1.1, 1. ],\n",
       "       [5.7, 2.8, 4.1, 1.3, 1. ],\n",
       "       [6.3, 3.3, 6. , 2.5, 2. ],\n",
       "       [5.8, 2.7, 5.1, 1.9, 2. ],\n",
       "       [7.1, 3. , 5.9, 2.1, 2. ],\n",
       "       [6.3, 2.9, 5.6, 1.8, 2. ],\n",
       "       [6.5, 3. , 5.8, 2.2, 2. ],\n",
       "       [7.6, 3. , 6.6, 2.1, 2. ],\n",
       "       [4.9, 2.5, 4.5, 1.7, 2. ],\n",
       "       [7.3, 2.9, 6.3, 1.8, 2. ],\n",
       "       [6.7, 2.5, 5.8, 1.8, 2. ],\n",
       "       [7.2, 3.6, 6.1, 2.5, 2. ],\n",
       "       [6.5, 3.2, 5.1, 2. , 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9, 2. ],\n",
       "       [6.8, 3. , 5.5, 2.1, 2. ],\n",
       "       [5.7, 2.5, 5. , 2. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4, 2. ],\n",
       "       [6.4, 3.2, 5.3, 2.3, 2. ],\n",
       "       [6.5, 3. , 5.5, 1.8, 2. ],\n",
       "       [7.7, 3.8, 6.7, 2.2, 2. ],\n",
       "       [7.7, 2.6, 6.9, 2.3, 2. ],\n",
       "       [6. , 2.2, 5. , 1.5, 2. ],\n",
       "       [6.9, 3.2, 5.7, 2.3, 2. ],\n",
       "       [5.6, 2.8, 4.9, 2. , 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. , 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8, 2. ],\n",
       "       [6.7, 3.3, 5.7, 2.1, 2. ],\n",
       "       [7.2, 3.2, 6. , 1.8, 2. ],\n",
       "       [6.2, 2.8, 4.8, 1.8, 2. ],\n",
       "       [6.1, 3. , 4.9, 1.8, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.1, 2. ],\n",
       "       [7.2, 3. , 5.8, 1.6, 2. ],\n",
       "       [7.4, 2.8, 6.1, 1.9, 2. ],\n",
       "       [7.9, 3.8, 6.4, 2. , 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2, 2. ],\n",
       "       [6.3, 2.8, 5.1, 1.5, 2. ],\n",
       "       [6.1, 2.6, 5.6, 1.4, 2. ],\n",
       "       [7.7, 3. , 6.1, 2.3, 2. ],\n",
       "       [6.3, 3.4, 5.6, 2.4, 2. ],\n",
       "       [6.4, 3.1, 5.5, 1.8, 2. ],\n",
       "       [6. , 3. , 4.8, 1.8, 2. ],\n",
       "       [6.9, 3.1, 5.4, 2.1, 2. ],\n",
       "       [6.7, 3.1, 5.6, 2.4, 2. ],\n",
       "       [6.9, 3.1, 5.1, 2.3, 2. ],\n",
       "       [5.8, 2.7, 5.1, 1.9, 2. ],\n",
       "       [6.8, 3.2, 5.9, 2.3, 2. ],\n",
       "       [6.7, 3.3, 5.7, 2.5, 2. ],\n",
       "       [6.7, 3. , 5.2, 2.3, 2. ],\n",
       "       [6.3, 2.5, 5. , 1.9, 2. ],\n",
       "       [6.5, 3. , 5.2, 2. , 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3, 2. ],\n",
       "       [5.9, 3. , 5.1, 1.8, 2. ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = np.load(\"data/iris.npy\")\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first four columns are numeric features (plant-related measurements... don't worry too much), and the fifth column is a label corresponding to the species, which is what we're going to use as our target.\n",
    "\n",
    "First we're just going to shuffle the rows, because at the moment they're in order (notice the label in the last column); in a minute we'll be splitting the data and we want a mixture of labels in each part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll separate the labels..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris_labels = iris[:, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... because Keras needs the labels to be \"one-hot encoded\".\n",
    "\n",
    "**One-hot encoded label:** list out all the possible labels, and mark the one which is correct.\n",
    "\n",
    "Here, our label could be 0, 1 or 2. \n",
    "    Is it: 0? 1? 2?\n",
    "    ---------------\n",
    "    0 =>  [1, 0, 0]\n",
    "    1 =>  [0, 1, 0]\n",
    "    2 =>  [0, 0, 1]\n",
    "\n",
    "Keras can do this for us..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "iris_onehot = to_categorical(iris_labels)\n",
    "iris_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get on with building a neural net!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to build a \"sequential\" model. The clue's in the name - we start with an empty model, and _sequentially_ add layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are plenty of layers to choose from, and we'll see some more exciting ones later on, but for now we'll stick with dense layers.\n",
    "\n",
    "For each dense layer, we specify:\n",
    "* The number of `units`, or how many neurons we want in the layer - the final layer will need to have 3 units, because we're classifying each input as one of 3 labels\n",
    "* The `activation` function we want to use - in a fully dense network, we tend to use sigmoid activation on the middle layers and softmax on the output layer\n",
    "\n",
    "And Keras takes care of everything else for us.\n",
    "\n",
    "Well, almost. For the very first layer in any model, we need to tell Keras what \"shape\" our input will be. We ignore the first dimension (the number of observations, or \"rows\"), because it can change without consequence; but we have to specify the other dimensions in a tuple. Here, it's a size-1 tuple, specifying that we have 4 features (\"columns\").\n",
    "\n",
    "Oh, and to add layers we use... umm, `add()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "model.add(Dense(15, activation=\"sigmoid\", input_shape=(4,)))\n",
    "model.add(Dense(3, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we've created..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 15)                75        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 48        \n",
      "=================================================================\n",
      "Total params: 123\n",
      "Trainable params: 123\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good!\n",
    "\n",
    "There's one more thing to do before we can train our model though: now that we're happy with it, we have to lock it in by \"compiling\" it.\n",
    "\n",
    "At this point we also need to tell Keras which loss function (always categorical crossentropy for multiclass classification) and optimizer (stochastic gradient descent, or something more fancy) to use.\n",
    "\n",
    "We can also ask for a list of metrics which we would like to see reported during training. These have nothing to do with the training process. The training process tries to minimise the loss function. Usually that results in an increase in accuracy. Once again - the metrics have NOTHING to do with the training process. It's just nice to see them improving as we train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit our model! We pass in our training data (remember that the label is in the last column, and we don't want to include that here!) and our one-hot encoded labels, as well as:\n",
    "* The number of `epochs` to train for, or the total number of times that all our training data gets passed through the network\n",
    "* A \"batch size\" - the parameters in the network get updated after each `batch_size` observations have been passed through\n",
    "* A proportion of the data which we'll set aside and use to assess our model's generalised performance (because a model can usually make great predictions about the data that's been used to train it, but it might not do so well on data it hasn't seen before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.1240 - acc: 0.3583 - val_loss: 1.0803 - val_acc: 0.4000\n",
      "Epoch 2/50\n",
      "120/120 [==============================] - 0s 96us/step - loss: 1.1248 - acc: 0.3250 - val_loss: 1.0818 - val_acc: 0.3667\n",
      "Epoch 3/50\n",
      "120/120 [==============================] - 0s 138us/step - loss: 1.1231 - acc: 0.3417 - val_loss: 1.0825 - val_acc: 0.3333\n",
      "Epoch 4/50\n",
      "120/120 [==============================] - 0s 150us/step - loss: 1.1241 - acc: 0.3250 - val_loss: 1.0834 - val_acc: 0.3667\n",
      "Epoch 5/50\n",
      "120/120 [==============================] - 0s 121us/step - loss: 1.1222 - acc: 0.3500 - val_loss: 1.0843 - val_acc: 0.3667\n",
      "Epoch 6/50\n",
      "120/120 [==============================] - 0s 142us/step - loss: 1.1232 - acc: 0.3333 - val_loss: 1.0850 - val_acc: 0.3667\n",
      "Epoch 7/50\n",
      "120/120 [==============================] - 0s 117us/step - loss: 1.1220 - acc: 0.3167 - val_loss: 1.0852 - val_acc: 0.3667\n",
      "Epoch 8/50\n",
      "120/120 [==============================] - 0s 130us/step - loss: 1.1228 - acc: 0.3167 - val_loss: 1.0859 - val_acc: 0.4000\n",
      "Epoch 9/50\n",
      "120/120 [==============================] - 0s 130us/step - loss: 1.1210 - acc: 0.3250 - val_loss: 1.0866 - val_acc: 0.4000\n",
      "Epoch 10/50\n",
      "120/120 [==============================] - 0s 146us/step - loss: 1.1206 - acc: 0.3000 - val_loss: 1.0870 - val_acc: 0.3667\n",
      "Epoch 11/50\n",
      "120/120 [==============================] - 0s 100us/step - loss: 1.1209 - acc: 0.3250 - val_loss: 1.0871 - val_acc: 0.4000\n",
      "Epoch 12/50\n",
      "120/120 [==============================] - 0s 96us/step - loss: 1.1198 - acc: 0.3417 - val_loss: 1.0871 - val_acc: 0.3667\n",
      "Epoch 13/50\n",
      "120/120 [==============================] - 0s 155us/step - loss: 1.1202 - acc: 0.3333 - val_loss: 1.0866 - val_acc: 0.3667\n",
      "Epoch 14/50\n",
      "120/120 [==============================] - 0s 125us/step - loss: 1.1198 - acc: 0.3417 - val_loss: 1.0871 - val_acc: 0.3667\n",
      "Epoch 15/50\n",
      "120/120 [==============================] - 0s 117us/step - loss: 1.1194 - acc: 0.3333 - val_loss: 1.0874 - val_acc: 0.3667\n",
      "Epoch 16/50\n",
      "120/120 [==============================] - 0s 155us/step - loss: 1.1192 - acc: 0.3250 - val_loss: 1.0879 - val_acc: 0.3667\n",
      "Epoch 17/50\n",
      "120/120 [==============================] - 0s 117us/step - loss: 1.1196 - acc: 0.3583 - val_loss: 1.0877 - val_acc: 0.4000\n",
      "Epoch 18/50\n",
      "120/120 [==============================] - 0s 155us/step - loss: 1.1184 - acc: 0.3333 - val_loss: 1.0872 - val_acc: 0.3667\n",
      "Epoch 19/50\n",
      "120/120 [==============================] - 0s 117us/step - loss: 1.1194 - acc: 0.3333 - val_loss: 1.0869 - val_acc: 0.4000\n",
      "Epoch 20/50\n",
      "120/120 [==============================] - 0s 138us/step - loss: 1.1188 - acc: 0.3250 - val_loss: 1.0876 - val_acc: 0.4000\n",
      "Epoch 21/50\n",
      "120/120 [==============================] - 0s 142us/step - loss: 1.1173 - acc: 0.3833 - val_loss: 1.0875 - val_acc: 0.3667\n",
      "Epoch 22/50\n",
      "120/120 [==============================] - 0s 125us/step - loss: 1.1175 - acc: 0.3417 - val_loss: 1.0877 - val_acc: 0.3667\n",
      "Epoch 23/50\n",
      "120/120 [==============================] - 0s 138us/step - loss: 1.1182 - acc: 0.3250 - val_loss: 1.0873 - val_acc: 0.3667\n",
      "Epoch 24/50\n",
      "120/120 [==============================] - 0s 109us/step - loss: 1.1161 - acc: 0.3250 - val_loss: 1.0877 - val_acc: 0.3667\n",
      "Epoch 25/50\n",
      "120/120 [==============================] - 0s 109us/step - loss: 1.1165 - acc: 0.3167 - val_loss: 1.0879 - val_acc: 0.3667\n",
      "Epoch 26/50\n",
      "120/120 [==============================] - 0s 113us/step - loss: 1.1177 - acc: 0.3250 - val_loss: 1.0887 - val_acc: 0.4000\n",
      "Epoch 27/50\n",
      "120/120 [==============================] - 0s 138us/step - loss: 1.1154 - acc: 0.3333 - val_loss: 1.0891 - val_acc: 0.4000\n",
      "Epoch 28/50\n",
      "120/120 [==============================] - 0s 117us/step - loss: 1.1155 - acc: 0.3833 - val_loss: 1.0890 - val_acc: 0.4000\n",
      "Epoch 29/50\n",
      "120/120 [==============================] - 0s 138us/step - loss: 1.1146 - acc: 0.3667 - val_loss: 1.0888 - val_acc: 0.3667\n",
      "Epoch 30/50\n",
      "120/120 [==============================] - 0s 142us/step - loss: 1.1156 - acc: 0.3500 - val_loss: 1.0885 - val_acc: 0.3667\n",
      "Epoch 31/50\n",
      "120/120 [==============================] - 0s 125us/step - loss: 1.1154 - acc: 0.3417 - val_loss: 1.0890 - val_acc: 0.4333\n",
      "Epoch 32/50\n",
      "120/120 [==============================] - 0s 138us/step - loss: 1.1144 - acc: 0.3583 - val_loss: 1.0887 - val_acc: 0.4000\n",
      "Epoch 33/50\n",
      "120/120 [==============================] - 0s 138us/step - loss: 1.1140 - acc: 0.3750 - val_loss: 1.0884 - val_acc: 0.4000\n",
      "Epoch 34/50\n",
      "120/120 [==============================] - 0s 117us/step - loss: 1.1140 - acc: 0.3250 - val_loss: 1.0889 - val_acc: 0.3667\n",
      "Epoch 35/50\n",
      "120/120 [==============================] - 0s 142us/step - loss: 1.1132 - acc: 0.3333 - val_loss: 1.0892 - val_acc: 0.4000\n",
      "Epoch 36/50\n",
      "120/120 [==============================] - 0s 125us/step - loss: 1.1130 - acc: 0.3333 - val_loss: 1.0896 - val_acc: 0.4333\n",
      "Epoch 37/50\n",
      "120/120 [==============================] - 0s 130us/step - loss: 1.1132 - acc: 0.3417 - val_loss: 1.0897 - val_acc: 0.4333\n",
      "Epoch 38/50\n",
      "120/120 [==============================] - 0s 125us/step - loss: 1.1135 - acc: 0.3833 - val_loss: 1.0898 - val_acc: 0.3667\n",
      "Epoch 39/50\n",
      "120/120 [==============================] - 0s 109us/step - loss: 1.1129 - acc: 0.3500 - val_loss: 1.0901 - val_acc: 0.3667\n",
      "Epoch 40/50\n",
      "120/120 [==============================] - 0s 146us/step - loss: 1.1122 - acc: 0.3583 - val_loss: 1.0904 - val_acc: 0.3667\n",
      "Epoch 41/50\n",
      "120/120 [==============================] - 0s 125us/step - loss: 1.1126 - acc: 0.3833 - val_loss: 1.0902 - val_acc: 0.3667\n",
      "Epoch 42/50\n",
      "120/120 [==============================] - 0s 150us/step - loss: 1.1130 - acc: 0.3500 - val_loss: 1.0906 - val_acc: 0.3667\n",
      "Epoch 43/50\n",
      "120/120 [==============================] - 0s 109us/step - loss: 1.1121 - acc: 0.3167 - val_loss: 1.0907 - val_acc: 0.3667\n",
      "Epoch 44/50\n",
      "120/120 [==============================] - 0s 96us/step - loss: 1.1118 - acc: 0.3250 - val_loss: 1.0907 - val_acc: 0.3667\n",
      "Epoch 45/50\n",
      "120/120 [==============================] - 0s 121us/step - loss: 1.1113 - acc: 0.3500 - val_loss: 1.0910 - val_acc: 0.3667\n",
      "Epoch 46/50\n",
      "120/120 [==============================] - 0s 113us/step - loss: 1.1117 - acc: 0.3833 - val_loss: 1.0912 - val_acc: 0.3667\n",
      "Epoch 47/50\n",
      "120/120 [==============================] - 0s 88us/step - loss: 1.1109 - acc: 0.3417 - val_loss: 1.0914 - val_acc: 0.4333\n",
      "Epoch 48/50\n",
      "120/120 [==============================] - 0s 146us/step - loss: 1.1112 - acc: 0.3583 - val_loss: 1.0911 - val_acc: 0.4333\n",
      "Epoch 49/50\n",
      "120/120 [==============================] - 0s 96us/step - loss: 1.1112 - acc: 0.3333 - val_loss: 1.0914 - val_acc: 0.4333\n",
      "Epoch 50/50\n",
      "120/120 [==============================] - 0s 100us/step - loss: 1.1108 - acc: 0.3500 - val_loss: 1.0914 - val_acc: 0.4333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27851e3b9e8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(iris[:, :4], iris_onehot, epochs=50, batch_size=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the loss keeps dropping, and the accuracy fluctuates but generally speaking increases for both the training and validation sets.\n",
    "\n",
    "So, that's the syntax, but let's be honest - it's a rubbish boring network and a rubbish boring dataset. Let's move on to something more interesting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look who's walking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset from https://archive.ics.uci.edu/ml/datasets/Activity+Recognition+from+Single+Chest-Mounted+Accelerometer; see data_prep.ipynb for details on how this data was prepared for use here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load in the data and check its dimensions, which is always a good thing to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6792, 260, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walking = np.load(\"data/walking_data.npy\")\n",
    "walking.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What? Three dimensions? Rows, columns and... huh??\n",
    "\n",
    "Don't panic. We have:\n",
    "* Observations - same as usual!\n",
    "* Timesteps - each column corresponds to one timestep, and together they form a time series. In this case we have 260 timesteps, forming a time series representing 5 seconds of measurements (because the samples were made at 52Hz).\n",
    "* Channels - at each timestep there are three values, one for the acceleration measurement in each of the x, y and z directions.\n",
    "\n",
    "As an important first step, let's work out how to visualise this data. We'll use `matplotlib` for our plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll plot one observation at a time. One observation is one \"row\" of our dataset, but remember that every \"row\" is 3 channels deep. We'll plot each channel individually but on the same graph..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_series(series):\n",
    "    # x-channel\n",
    "    plt.plot(series[:, 0], color=\"red\")\n",
    "    # y-channel\n",
    "    plt.plot(series[:, 1], color=\"green\")\n",
    "    # z-channel\n",
    "    plt.plot(series[:, 2], color=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we just pass in one observation from our data (one row, all timesteps and all channels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzsvXmYXFd55/+5ta/d1at6kWRtBmM5\ntiG2A9iAJ+CwhbAkhC2EYfLEk+AskDyT4ZchECYkTMgkJDAJE/YAMRkSDAbbLLYDBuzYlvAqWbZs\na+9Wr7Xvy72/P9577lJd3ep2V0nt1v0+j55WV1XX3c75nu/5vu95j2YYBh48ePDgYfPAd65PwIMH\nDx48dBcesXvw4MHDJoNH7B48ePCwyeARuwcPHjxsMnjE7sGDBw+bDB6xe/DgwcMmg0fsHjx48LDJ\n4BG7Bw8ePGwyeMTuwYMHD5sMgXNx0OHhYWPHjh3n4tAePHjw8KzFT3/60wXDMEbO9LlzQuw7duxg\n//795+LQHjx48PCshaZpx1fzOc+K8eDBg4dNBo/YPXjw4GGTwSN2Dx48eNhk8IjdgwcPHjYZPGL3\n4MGDh00Gj9g9ePDgYZPBI3YPHjx42GTwiN2DBw9rx733woMPnuuz8LAMzskCJQ8ePDzL8d73Qn8/\nfO975/pMPHSAR+wePHhYO3I50LRzfRYeloFH7B48eFg7ikUIBs/1WXhYBh6xe/DgYe0oFCAUOtdn\n4WEZeMTuwYOHtcEwRLFHIuf6TDwsAy8rxoMHD2tDrQatFpRK5/pMPCwDj9g9ePCwNhSL8rNUEvXu\nYcPBI3YPHjysDYrYDQOq1XN7Lh46wiN2Dx48rA2K2MGzYzYoPGL34MHD2uAR+4aHR+wePHhYGwoF\n+/8esW9IeMTuwYOHtcFT7BseHrF78OBhbfCIfcPDI3YPHjysDR6xb3ism9g1TYtomna/pmkPa5p2\nUNO0D3fjxDx48LBB4RH7hkc3SgrUgJ83DKOoaVoQ+Immad8xDOPeLny3Bw8eNho8Yt/wWDexG4Zh\nAOpJB81/3nI0Dx42Kzxi3/DoiseuaZpf07SHgDngdsMw7uvwmes1Tduvadr++fn5bhzWgwcP5wLF\nIiST8n+P2DckukLshmG0DMO4HNgKXKVp2iUdPvNpwzCuMAzjipGRkW4c1oMHD+cChQKoPuwR+4ZE\nV7NiDMPIAj8EXtXN7/XgwcMGQrEIfX0Qi3nEvkHRjayYEU3TUub/o8ArgMfX+70ePHjYoCgWIZGA\neNwj9g2KbmTFjAP/pGmaHxkovmYYxi1d+F4PHjxsRBSLMDws5O4R+4ZEN7JiHgGe34Vz8eDBw7MB\nxSLs2OEp9g0Mb+WpBw8e1gbPitnw8IjdgwcPa4NH7BseHrF78OBhbSiXIRr1iH0DwyP2TQDDgD/6\nI3jyyXN9Jh42PQxDNrOORDxiz2Q27J6vHrFvAhw/Dn/1V/Da157rM/Gw6VGryc/zndinpmBsDG6/\n/VyfSUd4xN4rVKtw7bWwb1/PDxUOy89crueHWhvuuANe/WrQ9XN9Jh66BUXs4bD8q9fP7fmcKxw8\nKNd+5Mi5PpOO8Ii9VzhyBO66C374w54fSs0Gy+WeH2pt+O535d+GG3G6gEoF/viPZTp+PqFalZ+R\nCASD5y+xK0J3bhO4geARew9gGPDQPSbLzs72/HhKEG84Yj91Sn5u0Ma/LvzgB/DRj8Lb336uz+Ts\nwqnYQyGP2PP5c3sey8Aj9h7gnnvg+b95BQ9xGczN9fx4itg3kuNx553w+Z9eJr84y7xuFjSb8vO7\n392cA9dycCr2UAgajXN7PucKnmI//7C4KD+nmDwrir3V6vkh1ox//Ef48NFfl182aONfF5yD1b/+\n67k7j7ONdsXeam3MBthreIr9/IOanWZJnVXFvpFQKhqUWmZUd7MT++nT5+48zjbaPXY4P1X70aPy\nc4O2bY/YewBF7BkGzlvFXso2KJKQXzZo418XnMS+Ga2m5dCu2OH889kzGchm5f+eYj9/oNp+lhTM\nz/dcUm9IxZ5rUCNCg8DmJva+vs15fcuh3WOH80+xO1McN+iz94i9B3Ap9maz5ylxG5LY83JSJeKb\nU9EWCrKsPpXanNe3HDzFLisCAXbu9BT7+QTLY/cNyX967LNvRCumXJbk+iKJDatq1gVVCCuxSa9v\nOXRS7OcbsSsbZseODfvsPWLvASzFntwu/+mxz+5U7BuldEWp4gegqG1Sq0IRezJ5/ip2FTw934hd\nLbjbutVT7OcT6kVp6NnomLxwFhV7pdLTQ60apbrs4VKMjW5eYk8mhdzPJ2KvVrmV13B8IX7+euyK\n2CcnpW1vFDXlgEfsPUA9Ix09o6yYs6jYzxWH6obOp/Z9ilK9hK5DxUx1LEZHNi+xK8W+Ga9vOdRq\n/CK3ctErJs9fKyaXk+eeSomq2ihqygGP2HuAelYedLaVBL//rBL7uRKPX3/s67zntvfwZz/6M1dp\ng2JkeHMqWqfHvhmvbzmYHnu1qm16Ys9UMlz5mSs5NH/I/UY+L9lQyaT8vgEHdo/Ye4B6QXzITCkk\nm/7Oz/f0eE4r5ly1saczT8u56C1XJddiaGBDNvx14zxV7K2Kg8TPgsd+/bev518PnpuVvXcevZP9\n0/v5ozv+yP1GLgf9/ULusCF99nUTu6Zp2zRN+4GmaYc0TTuoadrvd+PEns2oV0VC50t+9IGhs5ru\neK44ZqY4A8BYYsxN7MHBzUl856lib5QdfvpZ8Ni/8shX+Pqhr/fs+1dCKpIC4Fj2mPsNReybXLE3\ngT80DON5wAuBGzRNu7gL3/usRa0qwRTD0Mj1b7eLx/QITsV+rjhmtiR2UzgQdhN7ILUhG/66USjY\nir1atYuCbXLUy/Z1tvy9tWJaeotKs7KUWM8SKg2xVI9mjrrfOB8Uu2EYpw3DeMD8fwE4BEyu93uf\nzajX7Ch5NrEV0umeHm8jKfZas+b22P39m5PYnYpd/X4ewEns86WY+WJviL1Yl3t6roi93JCGXGq0\n7RKVy51fHrumaTuA5wP3dfN7n21wEnsmNnlWif1c8YtF7K2aW7H7+jYf6TUaks/tJPYN2Ll7gXrF\nnh5OZc8Osc+WZi31fDahiB1gvuSIk50Pil1B07QE8HXgvYZhLLlSTdOu1zRtv6Zp++d7HEw827ju\nOvja1+zfne08G97Sc2LfCMHT6cI0IIrdReybceWpukBlxUDPBq8HTx3kZR99H9VmtSffv1Y4FfvU\nYtR8sbfEDnA8d7wnx1gJTmI/OH/QfiOfd3vsm5XYNU0LIqT+z4Zh3NTpM4ZhfNowjCsMw7hiZGSk\nG4fdMLjzTti/3/69XgcfwraZ4Ih0+h5mDpxrKyZXzZGvSeNeotiJbz4PWpG4WqAEPbvxf/W5p/jR\nH/81//7w4z35/rVCJQYATKfNssw9Cp4W6vY9PRd2jIvY50xibzQkb92p2DegcOlGVowGfA44ZBjG\n36z/lJ5daLVk4ZlaaQ1Qb8Aostp0Rh+VF3uo2pcLnmaz8NWv9n5hoFNNORV7MlSlqMfllw3Y+J8x\n1E0+C4p9aqEA+HjgyY1R891lxcybxH4WFPu5JHYNzZqRWqtO+/shFgOfb9Mq9quBdwI/r2naQ+a/\n13The58VUEL0RPo0j84+CkC9obHLd5zt2+H7T+2WD/SQ2Dsp9sOHYWBAtuS87baeHRqA41kHsbdq\nlIoSYxiNlyi2Iu4T2wxwEnuPg6cLJWk3T5w6d/blj3+i8853NTEMd/xoej7IfVzFGz758z15vIXa\nuVfsYX+YodgQmaqZsqyIva8PNG3DrmPoRlbMTwzD0AzDuNQwjMvNfz2mko0DpYa/eeA7vPxLLweE\n2MP+Bq9/Pdx+YIwy0bNG7Kr43o9+ZL82NdWzQwNwePEwAGF/WBR7QVTdlmSZYtMk9s0UQFUd2anY\ne9S5F8tCKEdP53ry/avB//rig3zlSwGK5YbLijl5OsDNvJ6bH9nFBz/Y/eMqxe7X/OeM2GPBGIPR\nQdIVs/86FTvI89+kiv28hmUdt0KIKwW1hp+Qv8Ub3gCVmp/v8wtnzYpRs2Ln7LjXmzgdnD/IlvgW\nJpITothzLXy0GErUKdbNXOcNqGqeMc6CYn9k9hEeOP0A6ZIQycmZ8hn+onc4OiezhRPpGUuxj43B\n4SN+nmIPAJ/4BDz1VHePqzz2i4Yv4ql0l798FXAS+xLFroh9g2604hH7OlGvm1PTVpiByIC81vQR\n9jd5yUsgEde5k5efNcWuCF15/oFA77ddfWz+MfaO7iUcCFNr1SgXWsQpkYy1KNZMYt+AhZKeMTp5\n7F3u3DfcdgOv/MoraZjKYXa+gXGOqgjOZ2QaeDJjE/ull8LxEz4e5jL6wlV03b2xUDegFPtVk1dx\naOEQunF2d5QpN4XYByIDtmJX6txJ7J5i33woKu+jFSJblQL89ZaPUEAnGIQLthtMMdn11ae6odPS\nRaorxe73LyX27dt7q9gNwxBiH9nrsmLilEjEdYpVqcvuWrXUA2Sz8N3v9vQQNhSxx+Pyz/lal/Dk\n4pMslBfAkC5aK8Tl97MMwzDI5sVvdCr2Sy+V9w/zXC7bImsYuj12O4m93Ci7YjlOfO5z9vl0Eyta\nMSojZrN67Oc7ciZh+fUYmWoGwzCot/yEAqIuxid9TNP9RUof/uGHueqzVwG2Yo9Gl1ox27b1lthP\n5k9SqBe4eORiwoEw9VadUsEQYo8ZFCu9J3bd0PnYX+m8+tVwU8dk2y7Dmcfu8wm5d7Fzl+olq0SD\nInYqg1YsoxN+7/fccZVuYaowRbMqcZKp7JzVrpxEeumwZOx0+xEXagWigSiXbpGDuXLJHThwAB59\ntPvZX4rYByIDZCorWDGeYt98yJsyJUySeqtOtVk1iV2Uzfi4xmnfRNeJ/f7p+3lk9hF0Q7eIPRIx\nLGuoVhMFPz7eW2J/bP4xAFuxm1kxcUokkrKTko6GK7m9S2jqTQzD4I/v/GP+4d7PAPDe9/Z8cmAf\nIGauvOzy9nhHMg5Pw0Hsyy3SqdXgk5+EW2/t2ilYODR/COoSR5jKzFvEvnevJIUAXDp0Cuj+fS/W\niyTDSS4ekdJTqq21Q80Uuh2frzQqlmLPVrNiBXUKnnqKffMhX5HWHDSk8WeqGep6gFBQETvMGFsw\nFrtL7Meyx2jqTdKVtGXFLNRP8tiMlM+t1WT3si1bekvsauGGUuwqjz1OyZqtFkl0vdfrhs7uT+zm\nIz/6CF9+5MvkCuJFnzwJP/1pVw+1FKWSjJqqumE0aqcjdQGK2N/0vDcxGpuQF8tDnMqf6vh5VTzU\nuZaiWzi0cAhqEkc4nV+gbqrivj7ZyxngstQJOcVuK/Z6gUQoQSqSYiI5saxiV8TebX61FHt0AAOD\nXDUnzz4QsJ+9p9g3J/JlaVUBRL1lKm5in5iAuhEiPdu9eaJhGFb61+nCaTt4GqgynRUftl6Xtrdl\niyiZXqnY6cI0sWCModiQrdjLEKPM0KB8ZpGhrp/A4cXDnMid4KM/+SjThWnG/M+z3uv5vg/lsqh1\nJVnD4a6yqqpt/+lf/DS/f9X7APDVhpcldjUZ7AWxP77wOL6mjNAzuTT1ulxzKAQXXQQBGjwvcRLo\njceeDMmgsndkr736sw2qaXVbsTs9doB0Jc3BU/38he8D9m54SrFvsO3xNg2xf/GL8MIXnv3jquCp\nvyXEnq1mqetBa0AfH5efpzORrh1zrjRn1Q6ZKc7Y6Y6BKn0B2Y5PKfZRc+FrrzJjnJ1PKfZyRSNO\niaFhIYFeEPu+qX0AVJrCJhfGr7LeWyuxVxoVfu2mX+PuE3ev7g8UsStEIl1X7P3hfgajgxiG3EOt\n4lbs//zP8PznC5/0UrGfLp7G1xDbYSaXpt60if0d74DfSnyFhCFSuRdWTCIkM+E9g3vcFpUDvVbs\nitgz1Qz/349ezf+of4g77jA/1NcnQa6e+39rw6Yh9kcegfvug+89eceZP9xFFCrSoTVdlldnqhlq\nRpBw2LZiAKbzia4d07lYY6Y4Q6NpMnuwgt6UTaSdVgz0zo4p1Askwyaxm4q9VtMIU2NoRJrXgn+M\nSq7eVVGzb3of8WCc8cQ4V05cSaOUwB+XrCQVRGs2VxdQeyr9FP/86D9zzReu4ZuPf/PMf1Aq2dkw\n0BPFvntwN5qmWbMxvZziZM4m9v374aGH5FR6qdgLtQJGTa51vpCl1pRnGgrJquZPjn4EX7NOJNI7\nKwYgFowtWwit14pdpTGnK2l2xyRQ/Jd/aX5og5bu3TTErlTaq77wxrO6Ss1Kd2yaxF7J0iBEKCTK\nxlLspWTXjtlO7AslM5UyUKXVkCwUpxUDkhL28MNdOwULzs6nFHujCUEaDI3KuRwO7mXkEx/oajri\nvul9vGD8Bdz2jtv40hu/RDYLqSFpBNmS9PR3vUvI50xo6naBsrd9/W18/bGvc//U/Xzmp5/hq49+\nlUarbXRoV+xdJvYjmSPsGtgF2BlPhu7n5Jy9+lTF8DIZm9i7OGmwkK8VaFWlimOjDtmATEXVjJRQ\nCOp1YrHuEbtu6Hznye9QqNmiIRKIUGt1vsdnS7GnK2m0prSFO++Ush0btXTvpiN2akk7NeksoFiV\nxqa3ZP/HhYL0uFC4jdjLqa4dUxF70BdkpjjDfFGu1xeq02oKmbYr9s98Bn7rt7p2ChaK9SKJYJJj\nx2zF3mhoQuxjck/u4+coNcIcO9adYzZaDR6aeYgrJ67k8rHLuWj4IjIZGN8i135kQYJ5Tz0laXBn\ngiL2L77+i2zv386v/Ouv8HOf/Tmuv+V63n7T23nNja/h0dlH7QVCnYi9i6w6W5xlPCENx7mqeHa+\naQ0yWZmckMl034q548gd1j0plBpgmCmrepDFcO+J/VtPfIvX3PgaDi0cIhFKkMmAXu5HN3SaepNW\nC37pl+AnP5HP94LYdUOn0qxYwVOQ+FnNjDEAPPggnmLvNSxirydc5TZ7DUXsSikvmg9YEXs8Dn2h\nCqdrg1075rHsMYaiQ2zr38bp4mmrnkgyFljWigGxgruNQq1A7Ylr2b0b6plRU7ELsQ9sCaFp8Kgu\n6WrdCq4dzR6l2qxa+c0gRDcyIsRbrAj5FYuriy0oEhtLjPHQf32IW952Cze+6UaO/v5RPvu6z3LX\nsbu49P9eysfu/pj8QbsVE4l0jVUNw6BQL9AXFiXoXFVMZYDTRbECnMTeTSvm4ZmHue7L13Hz4zcD\nkC84TqAVouQTRlf7WDuJvVvP975T9j49yVCSd78bbv7LNwBQbVaZn4dvfxt++EP5TC+sGGX7tFsx\n9YbGQCCP3w8HD+Ip9l7jXBF7uSoHbtQ1EqEE6YI84FDEvrXjfSWmW6Nu+bUOHMsd44LUBYwnxpkp\nzpAuSS/vj4ctYldWTDgMTz8N11zTm2yRYr2IURhH16GZHxLF3hJi98cjDAzAobpUuOyWqFUrfIdi\nEiiuVITURrcIsZdrNrFnMme+bkXsAV+AaDDKa5/zWt72M29jR2oHv/GC3+DYe4+xM7WT+6fvlz/o\noRVTbpTRDX0ZYh+0Aqi9IvYn008CWLVZXEK0FaTqCxH0t6yEIEIhaDSIRrun2PdN77P+nwglmJ6G\n/JwEcGvNmnXt6tx6odgVh8SCMcKBMLGgLECsNzT6AmX27JGFUZ5i7zGsRu0g9n/4B7j55t4et2QS\ne72uMRAZYNE0P53EPtFfZpqJri3SmS/NMxofZSwxJsRelpYei2kYTZFSSrED7NoFQ0O9aXuFeoFg\ny1QtjbhLsROJMDQETeScukXsuarc4/6wdHbV0UdHhG0qVRlAlYI7k2p3EnsnTCQnuHjkYjsro4fE\nrgpfqUwjN7EPdST2bloxyuY7lj2GYRiUirb1QCtEVQsRDDii4MFgV60Y3dDZP23vWmMYBtUq1MrS\nmGutmnW97cTeTcXuJHbAKisglVtbXHKJp9h7jpO5k2QUaTqI/W/+Bj7/+d4eu1wTYq/VoD+cImu2\nLiexbxupcJJtXSP2cqNsZYTMFGdIV4TowmEwWkuJHXq3QK5QKxBoSfBUa8QwMGi0fELs4TBDQ/Zn\nuzVVV7s19UeE2FVHH9si97xSE6JWHX12Vgjyxhs7Z8mcidgBdg/s5un00xiGQaYY4Gtz19pZPl1M\nd1TXpoKGZ1Ls6XR3Fbsi9uO541SbVfRa1H5TD1LVQla5DKDrHvtT6afI1XL8wu5fkN8zT8mMrCwW\nULVZta5dPV913F4pdoC+cB+FeoF600co0GLvXonhVIOeYu8ZbrjtBvaffER+cRB7Pt/7+62m/QCp\n0DDZohw7HPNbr2/fUmeKSZrZ7kgKFdQZS4yRqWaYL0rPjkaBVgjd0C0rRiGZ7H46mGEYFOtFfCax\nG3XxnRu6n6DfAE1zEXvXFHtNBjJlV6iOPmEGayu1FvW6bcHMzsK+fZJ3/b3vLf2+1RD7roFdFOoF\nFiuLfHThet5y13v41rfMN7up2M3NJdS1tVqOAboySKFWQNc7Z8V0W7EX60WrnICcjCh2tfgO6LrH\nrtT6n/2nP+Otl7yVD73sQ1SrUCmZgqXpVuyG0X3FfseRO/jQDz8E2MQeCUSoNWtWgb9LLpFB9/HT\nZmmBDabYl2/JzyKcyJ2gWDZbdT1BqSHK+GwQe7VuE3t/YJSnyqZijzqIfaKJjp/pY3W2P2/JV6wZ\nKg3rsrHLAMiYVkw0Chh+itUStVq854q93ChjYOAzF2fp9Sj4EMVu5vH3VLGH3Yp9cty0fGq6a3Lk\ntGJmZpZ+36oU+6DECZ5OP41urhv427+F17+enlsx4bDwZ6k6SrU5TbFoK/leWTHHc8flXOqONN1W\niBodiL2LHvvRzFEALt1yKV/95a8C0m4atQC0AtRabo/dKRa60b7vPXUvr/vq66zgaTQgM5awP0y1\nWUUzC/xdLPkAPHYkwuU+n6fYe4HZ0qxlQSjFXq9LQ+/1xj3lmp0DnfAPkq+ITAzFbJLYvk06womj\n3QmeKmJ/5e5XMpYYA10Gkahp/2RKpSVWTCIh96ObFfCsPSkbJrHXoqD7MPBZWRM9Ueymx67sCtXR\nt46b0/Vay9XPZmftz8x32GFutYod4Ej6KXJNmZn88IeyMK6b6Y5q0HIGT30+uY/+6giVZsW6Fuhu\nHrthGBzNHiUSiFBulIVkXYo9SJ2QaybYbY89V8sRCUSIBOwULuu6akmqzapLsTvFQje49cN3fdh1\nbKditwr8BQ22b5f3p6a1DVkv5llP7LqhM1+atxYIUU9SbpSth9xzxV6zyTpMHxWzuqKL2HfIbT5x\nYv3HMwzDIvagP8i7LnuXVQEwHpWfuVKloxUD3b0f1i7yTVE1ej0CLTMdLrBUsXeL2PO1PPFg3CJi\n1dGHBn3ga1Cr6a4BfXbWti4WOpQ0Xw2x70xJxaun555gjlH6wiKP77sP8dgbjTZD/JlBWTFOj93n\ng8FB0CrDVBpuYk+nu6fYF8oLlBtlXrT1RQAcmDuwxIqpa23E3mWPPVvNWjMxcFst1PqWZMU4ib0b\nIm6mOMM126+xfm8n9poeJBSU/pRMmttObsAKj896Yl8sL9IyWhahKMWuBtBeK/Zq3VbsYZJUzY0I\nQvGg9fq2nUIYJ05prBf1Vh3d0K0Gd8OVN7B74DkAxExfP1+udgyeQpeJ3SQhoyEKp1kLgzlzUop9\neNj+fLesmFwtZylasNV4KgX469QaxhJiX69ijwajTCQnOLL4FHOMcsUFc8TjZsqbutFdyCe1gqch\nN7EPDYFWGXQp9mAQjh+Xz/j96yd2ZcNcu+NaAB6de9Sq7CgnoxS7ox13mdhztZwVFAcpC2GNl7W+\nJVkxzmN2o20vlBcYjg1bq02DfmnIkUCEaqNiXr9d4G9qCt6U/Tzvuest6z94F/GsJ3ZrQ4JliL3X\nhdeqdVuxB40EVZPnnYo9MRpjgDQnZ4Ltf75mqMCw8v629W/jHZf8uhzHPGauVDkrxK6sGL0hB2pW\nw6CbxG52fqXYNXSq1e48iPbOn8lI9mEoBJq/Sa1uE7umuRX7MyV2gB2pHRzPHWeOUcYG61x8saS8\nZfU+KnRnkZKaBTmDp0qxG5UBF7Fv327vM7ply/oPr+q9v+yClwG2Ytc0e/vHuhGyFt8BFrFHozJw\nr7ev5ao5l2J3iYF60pUV41TsoVB3RNxieZHh6DB3vPMOXnvha9kzKHu6OondXHzL5KQQ+48qV/Bo\nemL9B+8iukLsmqZ9XtO0OU3TDnTj+1ZCtVnlsw98lhtuvYHZ4iyzRSF2TRfVGGoNuYhd17tfQ+PG\nR29k+8e3U6qXqDuJnbilWEMJx3w1kWA7Jzgxu/6ln+1pWGCrulhEiKlQqZ1VK6ZlbljdSbG/4hXw\n3qv38WLuoVruzp6V+Vre1flzOXvfA1+gSaNhd/KtWyV4ul7FDqKiS7Ui84wwOtDkkkukZMHlf/NO\ndnKUb3+rO1aMT/NZz1ep8aEhaJUGXFbMzp32ZuqXXdambp8BVF+6aPgikqGk1D+vJ0gkDDQNAq2w\n1EGKtBF7o2Gl9a+3r+VqOVIRu/yG6/tMK6aTYh8ZWX/bLjfKVJoVhmJDPH/8+dzy9lssv12yYqqi\n2M2BbXISDh2CxWaKdDW20lefdXRLsX8ReFWXvmvlAz30RX7z27/JP+z/B95987uZKUqaQ0STnh3W\nByk1Sq5YRrftr0/c9wlO5k/yqf2fola3e1LQiFszh3DCoc7jcSH2xfU/fFWm1knsStUlInLss2HF\nfO6Bz3HL4Vvk+DW51mYtaCv2sDStVAo+/pZ7GSBDpdQlxV51WzGNhn2tml9SHRWx79olmTDdUOyx\nYIxiuUWBPkaGdPbulUHjeLqPIgk++L/iK/79apCv5UmGkmjm0k6nx94qJynXqy5iB4ndXX21/H89\nqn2+LDdnKDbEjtQOK90xkTQIhYTYm0bItUbDGTyF9dsx2WrWNRtzKfZan0ux67odOB4dXX/bXixL\nMb3h2PCS96zgKSFCZlubmHCsJ2h0r8hfN9AVYjcM40dAd7cIWgaHFw8TDUT55Ks/yXee+g6fuP8T\nAMRMYtfM4GkviX0sMQbAx+7+GLWG24pRxB5KOlg1GmUrU5zKrr9073KK3e+HeFRINVdsoOu9U+zl\nRpn33PYePrX/UwA06nLceiVEdoeCAAAgAElEQVRoK3anDxuLEaFKtdIdYs/X8kt8WL+ZXeoPNl3E\nfuGFEjBVe4k/0+ApyD0vZOW+j47CJZfI68PJKq/j22Ry64+hOMsgg5vYMfwUCz6LTHbskJ9XXWUv\nhF0PsS+UFxiMDhLwBbggdYG8WE+QTEqWk78VodFO7A6PHdZP7CtaMbWky2MHuxz16Kis/1vPjEVt\nFj4UHVrynhB7zSR2uf7JSfv9jN6P0erOjLQbeNZ57EcyR9g5sJMbrryBscQY90/dT9AXpNEwO1UH\nYi8WpfPfemt3/PapwhTRQFQUTstW5n49ZhO704rx+UgFi+Rr4XUffyUrJhGVY2ZyktPYK8X+4+M/\npt6yA4WNqlkquLpUscvJxohSodIlYs/VcvSFbMXebMpuZQA+v06zobmI3TDMEqsI8bSTz1qIvZST\nGzk65rOI/e3XnGSUOTK59XenQr1gBU7BHTwFKObCZLOSvqra+M/+rP2s10vsSq3u6N8BgNaKE4tq\nhELgb4VodgqeNhrEovJs1xsgz9XcxN7JislmbetNrVFQG8qsZ3H3YmV5xR72h6m2TGI3B7YJh61e\nI0Jl6qxo21XhrBG7pmnXa5q2X9O0/fOd5sOrxNHsUXamdqJpmhW9H42PWlt2GfW4K90RhMy+8x34\nxV/sTk3y6cI0b73krRI5120y8BtRK+3SRexAX7hGU/ev24PsROytlijWZEyOncuLclg1sT/9NPzb\nv8FjnTcLbsftR253/V6vm6WCKwFbsScd8QSl2KvrV7SwVLG3WjaxB4ItGg3Nus49EvviuGMf6Pbm\ntxZirxRkQBkd9zM5Cd/8Jnz4nU+RIku+6F93nbd8Le+ymVyKHSiZxJ5KwctfLq+985125c71tK/5\n8rxFakqxB1oJolFxXHzNEC0jvDTdEYiG5MKtQTOXg8cfX9PxG60G5UZ5RStGWVEqj1wpdlXFdD0B\nVEuxxzor9rrRcBG7U7EDpJ86D4ndMIxPG4ZxhWEYV4yMjDzT7+Bo5qi1WOTaC64FYEtii5Vpptdi\nHRX7aal2uu6dhJp6k5niDJPJSd6y9y2WQgXwtaK2Yh902y79EZFS613HsJJiT0bD5jHMlMvVWjFv\nexu8+c3wqtWFSW4/crt7RV5FCLtWDdiKvY3Yo1So1tZP7C29RbFedJGfU7H7g7Zij0YleKqgmt16\niL1WlMDe6IR89vWvh9SQnwHEH1jv83VuLgF2/EQp9ko+ZgWLr7tO3t+7t3uKfSQmN2lHagcAvlaC\nSARLsbeMDguUgFhI7qFF7B/+sJQUXQNUqueywdN60spy21Z5ArAVu3q265mRnsljB6gRtlaVT7Ql\nwqSPbZxFSs8qKyZdSVOoF6zFIkqxj0TGLW+tVY129NiVt+r0554J5kpz6IbORHKCD77sg0zELrDe\n8+sOYo+4b21fVBp+t4g9GrSLM6nOrxR7vrhUsYfDQn7LKnaAkyfPeIKFWoFHZh/h1y79NUDKqipV\nVS37bcXe7wgUx+NEqFLpArG3lxMAt8ceCOi0mj6KRbEr1EYnYKv35Yhd5Swvh1gwRqsknX5km2Pg\nCodJIcb3etuXsxY72PETpdirhRiViu2p+3zWKQDds2Iu6Jd27WtGHYo9SEtvI3bzwDG/HNgi9gce\nkMDGGkx3VY55eY+9j1xWLnj7U/8O2MRu3Z91zFiUYlc57ABPPCEDiSL2OiGrDtT4uKTTPneHHDRz\ncuMsUupWuuNXgf8Anqtp2ilN036jG9/bjqNZqSOxc0CI/TlDz2Fnaie7khdZn2lWI5TqkhWjakZ3\nk9inC9MATPZNMpYY483Ps/de01oRaEoDcJIqQF9MyCOXY12oNJZmxajOr9Idi2apVec5aNoyC+SK\nRUktUDuBP/HEisefKkwBkuvcH+4nGU46iN1nK3YnsZtWTK3hX3eMwSJ2wyZhp2IPBA2L2JNJ90Yj\nitjbA6hrUeyURolQITHiqHoYDluK3bkq9JlAZcUotFsxtWKcanXppinrJXbDMJgv2VaMUuw0Y0Sj\n5hqBTsRujpyxgkyFLSI+eFB+dopWLwNV3M1pxTiJ2ldPkTMD1Ns4Cdgz8IGBpZ9fKxYri6QiKasd\nPPkkXHQR/OAHJrHrPnT81hqVYBA++1n40/fLQdNTPdib8BmiW1kxbzMMY9wwjKBhGFsNw/hcN763\nHapAkFLsmqZx/2/ezweu+Z+AdORmNUKpViGfd/tu3SL2qbwQ20RS5mHO2iuaHobqAH5fw1WuG6Av\nISq6l1aM6nClgr2TvBMdif2kdBCuu05+nsEXdQ5sl4xeQl+4z+rMlbLPVuwDDivKtGJg/YtorMqO\nv/m7Eg3H7bEHg7KblVLsoZA9Tb/wQvnZrtgbegMNDZ+2cneIBWNQGSSlpdHijgcciXRPsdc6B09V\nsLBRii1JZYX1E3uhXqChNywrZjg2LHZbM2JZMVorhK4H3e1ql9ii0Xmpl1EuIzJadbi1EHtbnX2w\nB4q+PvDV+ykVTH8b6YdzcyJa1P1Zr2J3ZsSoUz92zCR2NRt3LD78L/8FXnydtPX0TA92snmGeFZZ\nMe2KHaQBBgzpZMqHLJfFZ1bBjV4odkXsTbuigBB7eYhEJG/vMGOiW/X4Vwqeqg5XLslUsb3zr0js\n114rX3ImxW4ObJPJST523cf46H/6mDW4VSqardjbiD1C1fzMKi5yBeQfl+h3fxVrEHJaMcGQgd4M\nUCwaJMxTUHbMtm1CAu2quqk3z6jWwbzntSQxX8GxNxxdU+yGYSwbPA0GQdMMjGaQStXoumKfL8lo\npxS7pmn8zJafgUbMsmK0RhCjXbGbxB6blb5ZLmOrdei8cGAZqEG7k8e+ZQtQ76dcEsoaQ9avzM1J\nLCUadX/+mWCxsujy11XcbnFxeWIHGBw1axYtdKfIXzfwrCL2I5kjDEYHXQ0f7Maspqt6LUouZzA0\nZC817iax+zQfo3HJr2o0HNPiRhAqg0RjS722bhO7Cl7CUsW+ErEvyRpQlcl275ZOukrFPp4c58Xb\nXsxLJ18JyD0ol7GLgC2j2Ne9MvER2Z6ur4Z1M51WTCgItILkC0uJfWBA7kH7M1gTsdeTRANtOXVd\n8tirzSoto9UxeKppEAg3oRmhWtVXr9gzGfjIR+DHP17x2MpfdhLbbW+/jTD9thXTCmC02oh9YABS\nKWKnJU5TKuEm9mei2DtkxYyOglbro6x+R8x1XRdSV31wvTEGZ0aMk9jDgbBN7HF3LCYehwANa7HU\nRsCzitjff837+cZbvrHkdfUArEqC9QS5vEFfn0zHz6jYjx6VefqTT57xHKYKU4wlxiwiaDYd+xoX\nW1AZIpJcmkzbl5JbvW5i/8oXCOJ3BfraFXu1bJY1WI0Vc+KEMMfEhBiKZ1Ds04Vp+sJ9JELCmqrj\nDQ+DYWhQkxEsOOhYiddNxb4gM4b+QMxadeS0YkIhDVohCkV9CbGnUjJlb49zrI3YE0RCbRcRiXRF\nsVsFwD73ZdnXETt+AhAKtaAZ6ajYOxJboSCrqP7kTyTj6d57lz22IvaRuJ2xNhQbolrRiEREsRvN\n4FJiB9i1i+SUCIJiESF29aE1KPZOwVMlBEZHwaglqFakH/WRJ6qZ8aZYd9I9F8urVOxtxK5pMBgs\nkM5vnO0tnlXEviO1g5de8NIlr6sHoBQ79QT5gqhkRWYrEvsDD0g1pW8sHTTaMVOcsVaegih2Reyt\nTA0qg4Q7EXu/eDPrIvZmk/Kpo8Ra7sfWrtjrJrGv2ooZH5ee+9znykoep7/UhqnCFJNJO4HXSewA\nwapZFW/IQezhMBGEcdat2NOSt9rXN2oRu1Oxh0OAHqRQYAmx9/d3Lp29VismHG8rah8Ok6CI36ev\nS7ErK2Lgp49JxA772QIEwy1oRlcMnrru74EDMD0NH/+4PKA//MNlj63KCTiJzTDk+5RilyqevqXE\nvnMnkWOPEwiY9/aJJ+D5z5cR6RlYMc4ZuVOxG7Uk1YqMcnFKJJHGrDZtX3L9hrGmDeTbPfZliT28\nNLtrMFImXWy/MecOzypiXw6dFHshbxP74qJNaB07ntpW5447znis+fK8FWACIXYVKG1kSmjlQYLJ\npSle4f4IIWrkc+tIC8lkKAch2nI3rHZir1WklbcTu6rA58KJE/Zqjxe+UG6mSSqdMF2YtuILYH+f\nuvcBRewDDmLXNKJhCR6vl9jzeZmC9yeHXcRuq1oftEIUi5pF7CqXfXBQ2sT6FHuSULKNLMJhNCAV\nMeuYGIasXFrjriZKsaaqCCHjJvZQ2IBmZPXBU7Xc9jWvgV/5FREwy5xTJytGPSvlsTcbomA6KXbt\n2FH6+gwh9qkpaVNDQ2u2YuLBuGs2WqnIoJ1KyRoVpdhjlHmV8R3AbYfam3LU4LWvldjRKlBtVik1\nSi5iV/fSIvZm534FMBirknHuD3uOsamI3VLstT5KRZ9lxThXHXb0wRSx/+QnZ2Se+dK8a7rabEpD\nDwahlq1gVIYI9HdY/haP00eefGYdAZbFRSpBiNXdg0O7FdOomMrC0QEXy4sEw42Vif21r5Ue9E//\ntOwpLEfsSrH7KxL4cpUUwO54615yXsrgNzRi/cMdrZhIWDJzyiWb2N/xDvjSl+Qy+/vXodgJQi1J\nsK+tJojZ01MRc3efhx6CN75xzTupn4nYw2FdiL2qrS54eviwNIydO+GKK6RtO/1vBxbKCwR9QVdG\njuoKKium2RQFEwy2iZNdu6Bepy/ekns7PS3W3sjImhW7019X5xCJSD82miGqRbnwGGW+yH/mln9a\n5MYbOxD7DTfIcvOf/GRVgY9Oi5MUrywstCn2DsJ8IFYj3exb+sY5wqYg9vbgKcUxDEOzFPuxY/Ly\n5OQyz1glw1Yq8B//seKxOin2YFAedm6xAc0Yvv4OBStiMfrJrY/Y02nKQYhV3d/Rrtgb1aXK4rov\nX8ddU99zE6thwKlTtqSNROAtb4GbburoGemGznRhekUrRlPE3rbWJxoRMliXYjcMcvUcfYTRhoaX\nsWJ80IhRr/ksYu/vl2X3sE7FvpCDepJAqu0ZBgLg8zEQLotiN0mZm29e0+UtIXbDsIKnAOEIpmLX\nVq/Yd+2Sh3HllfLavn0dj52upBmKDVlVJcF+tkqxN8wtAf3Btus3y0z2hark02bN5MlJIfY1KPZ0\nJe1aHKTOIRq1V05Xs32E/E0CtNCA114+xdVXtxF7owFf/apdpe2ee854bFUnZrng6RmJPdEgrad6\nu/nDGrApiH2JYi+IolTE7iwIVSh0sJBnZuxSeffdt+xxyo0y5UbZRezNpjT6cBhm5sUP0JIdViEp\nxZ5dn2IXYtddK/qUYldk2jJrQ6vO3tJbHJw7yNHiQcoVh9rM5aQnONdGv/GN0pseeGDp4cuLNPTG\niopdq4jiaif2SFRzff4ZYX6efECn3x+TaX4HKyYa9kFVBpdEYulXrEexh04tQjOKP9XWeTVNMmNC\nZREOajnknXeuaY171rSZUuF+adSLi67gaSRiQD1Oq+lbvWJ/juyuxe7dMhvbv7/jsZcjVTA99qBB\nvSk3VPO35WubD78vVCO/YL43MSGvr0Gxt3vc4FbsANVsP7GA4/gLC3z7iW/z7lvfBpjX//DD0j/+\n4A9k0L377lUdGzor9sVFCPtXJvZk3KBIonvbhK0Tm57YX/Qi+3Nq5eGSzIWZGQkcjo7aW9J0QKfM\ngUZD2k4oBKez4rEZkcWlfxyLCbHnkFH9f/9vOHJktZcoUMTewFaF2Ipd02SjCaMqvUA1wOnCNHW9\nDoEK9ZrPLm2qLCjn8kwVaeygtNpz+GGpx07FzIppJ/aYEHuxvArfeW4O/vzPl47AJ06QCyOVHYeG\nZMSu192KPexHNetkkiVYj2LXn5aG40t1KM8aDjMQLErbUsRer8P3vnfG71XInpSsrNRLzMVi09Mu\nKyYS0aDWb/7f/bdLsmJ0XbK8FLFrmtgxKyj2dmJ3euwhf4umIQfRAm3P0Fz2mQxUKCjhoqyYNSj2\n9jxysBW7IvZ6PkXM7yb2bz7+Tf7t8X/B7zfknBWRX3edBHFXQezKiukUPG02oVmJrkjs8TiUiPd+\nL85VYlMRu0UuJrEnk3D99fbnVBtfYsfMzsLYmEj6FYhdLeJYTrGfLkmn0yMdGrNS7HkkvfK//Tf4\n279d7SUKzkDsAIGgbm1ArFScWtgV0aSnWnaIsqDG7CwfS3p36JBqG0JnVlC7Yjeqcg/aG7+WEJX7\n1QfNzKNaDe6/v/N13nQTfOADS4PZJ06QD0N/bMB+2Om0y2OPhR1bEi6j2CsVdwxxtcTePCINR2u3\nYkBWnwYcxB6NygNY7ho7IDt3nGALoi97hbwwNeV6trGoZs1G2q2YQEC42yL26Wm5UNXoQer7HjjQ\nMYC6kmKPRCCo2YNsvK8tWdwk9j5/SYQL2Ip9cXHVmSnLKXanFdMoDBD3V+xUtMVFq32Hwrq07Z/8\nBC64QCzGa66RWfgZUplXUuwApdzKij2e0KgQQy+UZJZy0UWrSsboFTYVsSeT4PfpUBTV2dcn/95u\nlnNRit1F7IYhynVsTD6wQgNQKWHLKnaz0zUjHUpIKsVe1CS4Bmt/8E5in5qyXlZWDJjErpu7OCli\nX5Br2l4U+8aaLSrF7iR2RZiLS2cd7asTnd+liF2vdrZi7pmQHn9w2pyl/M3fyHSqk6JT59XuUZ88\nSS4Cfclh13k6FbuqlwOdid21UGzfPvjAB1ZN7JWjZuQ92iGGEg4z4C+QToMxOyf3dOtWe2XvKpBd\nnCZVBe1lsudou2J3Enu7YjfdIJvYVUaMk9j37pUG20G8nNGK8dnEnhhosxv6+0HT6NMK5M2VoZZi\nN4xlMhbcMAyDdCXdUbE7rZhmYYiYVrUD/gsLFrH7g01bsastpd7zHiGG665bcfawkscOUgd/RWLv\nkw5YXijDJz8pKZ933nnG6+4VNgWxq8YcDkMy1nJZMQBf+Yq0LVWM30Xs2aw8wS1bRLFPTy9brb8T\nsangaTgMdXM5fSPUgdiVYi/67KLwhw65CPqMWFykEtRWVOxOQlUN8OjpQ2gG7ChJhyyXTY+4vZg1\nyIUkEh07QaeBrZ3Ym7XOxP7tLXKdJxbnpOjWTTfJiXciPnVe3/qWe0ucgwfJR330J0eWELvlsZ+B\n2FVNkXweuPFG+PM/p5nLrIrYC6dkcDKCHRYjhMMMBzKye9PpgjS27dvXRuyFOVLNgLVMn+lpV/A0\nFvWDOXB2SrkLhx2zseWIHTpmxqQraQYjyxN7ULNVfjzVls5rFrPpM3LkK0Eh0mRSajiAzFDPgHwt\nT1NvLqmFrhS7epZGLUFcK1m5q42FWU7kZPW0L1inWm5Jje6LL5Y/2LMHbrtN+tl//+/LHn+hvEAy\nlCTkt1nbSeyFdGBVxF46vgD/5//Ii2dY7NdLbApiVw8gFIJEpAkFW7GDqJmBAbsCnIvYnXaEkvTL\neN+Wx95mxQQCbm6sh08v/WNTsedKAVHsqrjFv//7qq+TxUXKER9RAi5idyr2UMgO7ClyPTJ/mMk8\nDJmVIRfy5sA1MyMnP+ju0AwPdyb20jx+ze+q5dHusTcbQjzqfACK9SLfH5Cc00bdz2MHfmAH8U53\nuFdKsU9Pi6p+//vhC1+AffvIxf2SEucgdqcVE4/YI8pKij2XwwrsNWemV0XsxZK5D2moQ3A8HGbE\nJ8p0/nRTiH3bNrtkwyqQrWRJ+WJ25TLTilH3Mh7zgSHn2a7YzVNwK/Zo1B0Yv+gi6QxtxF5r1ig1\nSst67JEIhLCJPdJvB4R1Q2e2OIsxkKJPz1BuhmmOm4S+wkDSjk5WCCxV7AAxoyQvjIxwMnMc3ZDB\n3whUqBbMmYUzwHLllbI46/OfX3b17WJlccmg4gxEp09U8Nc757GXG2XUmqri9+8RghkeXvNGI93E\npiL2cNgkdrPx90Uboo5vlx1/1LN2xTecdoQq/7eMHTNfnifgC7iITSn23/5t+3OVTtu/moq93vRT\ne+iQbOc0NAQ//OHSz37pS7bicmJxkVLAIBaOu5S+axGLuW1ZIKhbhciOZo+xKwOplrDwTCZnX/uW\nLfYfKwwPd7ZizB12nFUQFbGrsaHVioG/7iqCdmj+EPWQqfIaUfbd+SX7zeWI/YorpPO+973wl38J\nf/qnGAceJRdoycpEdcAlVszKxO5S7GaQszk/szrFXhOp1gp1qBsQiTCiCTnNz2Mr9qmpFVfyWjAM\nss2iZMSAEHKbFROP2ue4KmK/8EL3s43FZDbQRrSZqiidgeiA63WXYlfE7q/hC9uK/csPf5mxvx5j\n75tmMHQRSYUtpkDatUtOdBXEblkhbR57e7ojQEw3iX1sjKMFmREFfAF0X5lqsQOxg5RV6O+3SjW0\nw1mLXsGp2BdPlgk2Oiv2X7zxF/lc+t8AU7EDvOQlYnmt5tn3AJuK2EMhSIRtZZEszcgD/Q0pD9+x\nnoQzM0Qp9j/4A/jgB5ccR9Wrdub6KlJ5wxvsz1WaS1eePt2c49SwTOFzJ7LwghfA5ZfDo4+6P1go\nwLveJVk6bTOHRnqBUkAnFRu0N8egfRGLnFtywL7Io+UpdmZhKCDvzeVMxTU7655qKCyn2MvuxVlg\nd/5YDKIR0zbxuYNzR7NHwacToE6YfvZN7bOJuROxz87K9V9/va2wTpygRouGpkstkeWsmLA9VVi1\nYi/kaU/N7oSCqdga/g4DdzhsE3vabyt2Xe98je2YmyMbbJFKmNc1Ogrz820eu91dl7NiXMTutGEU\n9u5dQrTpilzPih47ZieLLlJr2W3rwZkHCfqCHEpWeTR+DID84A550++XWYI63pNPygrYX//1Jfne\nC0flM8P/x72oqz3dESCu54W4x8c5WpP++8KtL6ThK1Armw+yndjjcfjVX4Wvf71j5spieXHJoFKv\nS4YoQPp0rSOxN1oN7j55Nw9VJD24NG2Kphe9SFSf04aq1eCWW85K5symIHbVmJ3E7vOXCc6eEgKc\nmoJ63XI/XKmmygMdH5dev2uXLFX9+79fcpz2xUlgK3a/H+7b8w7e9Au/Y1VgdOIvHv0H/u9LzEJR\npGTxxN69ss+o00d2kvnv/Z7rO7JFIaKB0R2S3WCqAacVEzGJfefPSIOvt+pMNzPsyMLQmDTchZzD\ninEGThWWWQru3DpNoVoVQvH5IB41r8PfRuxmHf04ZQb9F/C4tijHHRhYSnrOYPZ73ytf/o53AJAz\nyawv3CcdNRRaotid3r6L2ItF+JM/od8vncpS7P39NH0QaJ6Z2S1iD3RY5RYOM2Iq1nl90FbssDo7\n5vBhshFIpcx0U7P+g5PYo1FbUHRS7JGI2RcaDWlHnYj94ouF9B1yNFOR61nZijE/H8lRbdrEfiRz\nhIuGL+Kq8gAPDZ4CID+8y/4S50Dy5jdL3OTLX5YFRA4sfvzPARj655tcryvF7tzfINIqWNtjHUHi\nIy/d/lLqWp7ycsQOIpjKZSH3Niyn2GMxoYXMXINAB2J/bP4x6q06Fb/MOEozpmjqtHHNvffC6163\nNvv1GWJTELtLsYfkFy2cF9I+ckSI89Spzor9pz+VDqgM+HvuEaVYLi9RFZ0Uq0p3BLgq8ADP33MX\nDb1Bo+UmtydyRzBioowWGRLi2rtXArXOjq8yFq69ViwktcDFMMiYympg+4VyEaZl5Oz8i/PCcFsv\nOSa/lxcxMNhShOFBmeYv5MyBZ62KvdRZsasBMx4xO1UHxT5EjC3MohXHyFAVKTQ+vpTYi0X50rEx\nUbxPPCHe6FVXkd8qHa8/IlkYpFKQy7VVd7S/yqq6CTIL+8hH6PvRLQDksoYo9slJIfZVdIVCw9z3\n0t8huyKRYKQmxDbPiK3YYXUB1CeeEGIfMf/GJHZn8NRJ5p0UezJpzkSOHpXRvhOxX3SRNFq1HJvV\nKfbgvBnTiWStXbwAns48ze7B3byxsYenh+R7CoP2dpHs3SvXrza3/p3fsT1vZVM0myzMyvkMl3Gl\nYyrF7vdDMCKvh/ScRexHY3W2J7dx4dCF4K+RL9Xsm9GOF79YFmp96UtL3lqsdFbsoZBMLjNpvSOx\nP3DaXMgXFLFUStfk2Cq+4CT2O+6QC1FZTz3EpiL2YNAmdsJ5CdApFj9+nEBACMCl2Pfvt5dbgxDd\n3r3yd20+82xx1qrDrqDSHQGo1Yj7pMeVGu7MmsPpJyEq37fIoKjiTsElZbG8733uBS7lMhmTMAd2\nm0ulzewaZ4BtdkYe6chF0qCUdzmsxRntEwmbKVTJZXQ7f78dw8MyoDhNRkyPPdp5AQnYGxrja9DS\nbQV8NHuUnb4hxjlNMzdMxl9bntjbF01dcIH0pH/8R3L/68OAo/pfKgXZrLseu9npfMG6rd5rNfjc\n5yiEoF83N52eq8rD27pViN04836shWYETWtSpYPHPjhIPDdNOKSzwLCb2Feh2GuHH6MSXErs7pWn\n9uc7KXarNEunjBgFc/n/Wok99JiZohvOUazLrMcwDI5kjrArtYs3hC6VPgfk+7fZX6La+I9/LM/h\nggtkJjYzY9uQTz/NYriFXzc3UHGICjUjBojEpD2GDVuxzyZgPDQoaysCVYpVc9bYyYfTNLGBfvAD\n1zOpt+rka/mOij0UEs2XyWj4m52JPRFKsGNEeKFETEaCwUFpwyq1GYTYr7zSDvT0EJuG2INBUTaJ\noDz8VriA8U1HGV6zIbsqHKbTQqRXXOH+wg5T6GqzytHsUZ4z6O4sTsVOrUa/T+aMatMAkBog8+V5\ntraEEJ6MnoHYh4akIt/goJ3LPT9PxiTQgQsvlYOajcap6hSiW6Vzq2yDoXCKLf3S2PffNUpq0Mc3\nm69dntjBNbA19SbpSnplxR5UAbYGlaY9eh7JHGFnaIQJpqllB0kHmmcm9vbzuvxy8pfJ3rZWve7+\nfvRsHsNw7KBkPotAxDF633wzB4d0Uu+HT6e/QSAgVud3eeUaiT1KIFzqGENhcBAtk2YkWbUVe1+f\nXKeT2ItF+Jd/WbL0PLOJcVMAACAASURBVHvkMQCJn4B4AEusGPvznYjdtOXtWZ9KBnBCEbvD+12J\n2DUNQtk5gkfNwSKSs9rU6eJpqs0quwd3s6dvh03scccO4s97nvxU9sPWrXaOuVoRevAgCzEY0mJo\nYK/cxV0HKGLuGxzwly1iz0Rg0IgIKQeqVFSMoZNiB9vf/8pXrJeWy8hxEXvBj9+s7ugi9pkHeP7Y\n83nRrksBc/Wpmv1fe61ct2HIjGXfPnjFKzqfV5exaYhd3exEQBmDeYrHHQsxfvADeN3riKjVaSA2\nDLgVO7CQ3MEcI64O+fjC4+iGziWjl7g+267Y+/0msddsYn9yUSyT/2R62yfCI9LwUinJfmgn9t27\n7YjsN74h6VMHD5I1O3MqOSJeqUOxq87/nvdA5KIfUDQHEWfVuoE+ObeTj8uU8638C9XJ3UtvqApM\nOpST+p52j91N7KbC9zUsH7altziePc7O8DjjnKac6acUMGikkjaxOy2vTqthTajB0qnYWxkhkyWK\n3ZG5wbFj3LMNdB+8L3A7zSbc/UCU3+QzayP2VoxQqNwxhsLgIJTLjEQKNrGDiASljtWGLm97m4tY\nALInhDitjKtoFMrltpIC9uc7WTGK2PXTszLCDQ0t/dDEhLzXRuw+zbdkZzJlg2jfuQ31hPzRkkWE\nRzISD9o1sIvA4DD9uknsIQdB7tgho64qBb11q9yTyUkXsS9GHRkxjvoyrlXFcVHj/oCdFZOOwmAz\nYBN73bxZyxH7jh3S381MOZA9FkB2BXOiVnMQeymET4+i+VquVN5HZh/h8rHLuXhS7Ke5YNxODHjF\nKyRl9/HH4a675GI8Yl891AMASAZN1g7nReFqmsxRv/xluOUWokbZFkuqbsbP/qzr+/7zXz6P13Cb\nyxs9MHcAoCOxW4q9XiflF1WsKvUBPJkWYv/5gg7oTMfHsPIB9+51Z8YoYgf4/d8XD/5Tn4KHHyZj\nduyByABceqn1d87g6d//Pez5vd+zSNBS7MlRYgPyBeW8sEKNCN8sXbf0hnYoK9BpcRK0EXvAlEv+\nhuXDThemaegNdsYnGOc0jVoYan1kUhEh9nrdvbCgU/0aE0t2se/vp2kOlu3BUy3ksMLm53l40k+y\n4SNgaPRtkeOdYhsziT1rIvZwqEyh3qGwl9mZR7QFIXZ1D/fssRX0v/6rvXbg0CH7b5tNsnMiIlzE\nXqmg60ZHYm9X7Lc/fTuR/jzNJmRPFc295Dpck9/vHmwQYh+IDCzZzNt6tgcPkvML6caSdRYqbmLf\nPbAbBgYYbZrEXnVI2mBQyFQtytu6Vc7r6qvdxD4YYShhDobLKPZE0hxegmUrKyYdhYGKJoNCoEq9\ncQZiB5m1ONaBnC7IrNFZKgPcij1diQqxO+rkVBoVivUiE8kJLpmUmdCJmEOxv/zl8vOOO+RfNGoH\nVXuMrhC7pmmv0jTtCU3TntI07f3d+M61oKNiD+dJRxGF4vAaI42CrdjvvRee8xz0vhS33WaXtDhw\nOMRPuYKjj9gd+MDcAYK+IHsG97iO7Wx41Gr0B4XYnVbM4cXDaGhcUx6AaIbZgMOnf8ELJMOlWpUL\nOXHCJvZLL5Utzf7u7+D++8lMSIMZiA5IZzl9GppNl6oDUbRqmzUrPzg1QTQlhF7O2h7f8dMdltF1\nsGI61cmBNo/db95Yh2JXy713JS9gHNN2KYyTSQbtgmNOO2ZmRi6mg9pU12RZMakUzaz4vfYCLfPD\nYUdK2cICD0/6ubTaz9ZKkJf/xR/zvd+/FYB9xecJsetnIHZdp2AkiIar5Ko5VwwBgMFBDg2Dbhxj\n3rfFbhQXXigB/FZLiOw5z5GMKOfilWPHyJj5li5iNwxazTMr9vnSPK/8yiu5e+GbAMxNN0XMLIed\nO92Kvbq0nADYi4OYmiKXkFLNyT7dagtPp5/Gp/m4IHUBDAywpeHIOHJizx4sv0zNxK6+WoTTvn1w\n4AAL/UGG+8zB3CR2tQGSRexxeUZGqAzxOI2BfophGCy1SIQS+EIN6o2AvRR8OYyNudqcpdgTbsXu\nsmLqcXxGFM2R8eW0sC6ZeA74GpwKJ2zFvnOnZNl997tSXuClL135vLqIdRO7pml+4O+BVwMXA2/T\nNO3i9X7vWlCv2/crETDleDhPJmkuz1YlecNhouU0lYohreaee+Dqq7npJtlj4q//Wr7r5ElpQDfv\nt+uOH5g7wEXDF7l2dwGHYjcMqNdtYndaMekn2d6/ne30Q3SRRc2xEOTKK+VLHnlE0ix13SZ2gN/9\nXWno3/42ma1DRAIRqQ09MSGfnZtzBdhAiE8df6E0T7wOkeExooPCwHozxCCLJGNNp3CxodSyYxFU\np8qW0KbYfea9d3jsJ3My69nWt80m9uI46YTPJnZnWYWnn5YAm/OCTKhZUEA31Vh/P8282CLtit0I\n2sRuzM/xyFCTy7RxtmcN5rUDXN1/EB8t9s1speGDwJnKaDcaZEmRjFYxMFzPF+BT9bu5+Hfgjm2H\nJXiqsGePPN/jx+0aJu17yx4+zIKZzmcNnOZN1Vt65+Dp0UPwiU8A8J2nvoOBwSldMjTmZ3XbCuqE\nNmJfLC92JHa1nJ/pacqm/9zfb1ht4XjuOJPJSVmGPzDAaEXHFyp0JnYQQlUX85a3SHD5ZS+DgweZ\nixmMpibl/SNH4AMfoFUScaCebV9S6MoIlSCVIlOXZzCYq6MtLBD1NWg0Q50Dp06Mj0tygFk65HRR\n2uWWhHuWqHhlYABqRhijMQCOypJOYt+R2gGhIrNhh2IHeOtbZcOPxx6zFfxZQDcU+1XAU4ZhHDEM\now78C/D6LnzvquFS7D6b2NNvfJXcWBUwet/7iDQLVBdL0rEWF+Hqq62tTv/0T8UKU2nlNx+xbZeD\n8weX2DC6LnweCGBlkPSHxKd0Kvan0k+xZ3APoVgSfzhNtuXoRMrf37/fzohxEvsv/IJ0CF0nM9on\nNgzYS8Xb6olAm2IvzEoK2dAQvr4EPp/YJSmyTE4YnUvVjIzIMR012edKoqI6KXZFOHFM79nntmIA\nJge2uxV7zNcxQ4PHHxfi64DpwjT9c69hdCgk6f6pFK2q3Pd2j1131HM5VpwiH9S5LLaT7QsNTmRP\nEM9OcYnvMfY93mcq9o6HtFGvc5JtjKbkuapOrfCZhe/Lf2ILFPSEvVBIkdqtt1rtjec+V4hVTR0P\nH2beJHYrgGcR+zJWzP/7J7Hq5ua47cnbADhSl01i5hb9Kyv2HTvExzaJrVO5XHAM2tPTfODK7/Hu\nd8Nlr37AInbX/r8DA4yWgHAHYldBXLWhC4h4+P734bLL0P/nh5nXyozGt8hs8QtfkBo+P5INMtSz\n7TfrsbRCZRgasvLvB9IV+MIXiNUKNJuhlW0YsAWFafudLpxmIDIggskBp2IHaFa2YCxD7AFfgECg\nzHzA4bGDCDPVKM+Svw7dIfZJwJmoe8p87azB6bEn/A5i/9Vfkmjib/+2+JvvfjdRKlTmipa/V7/y\nam69FV75SvmeD31I/vwlW57gx/nLyOWgUCtwLHuMvSN7XcdV6bbBIDaxmzaBU9Edyx5jZ2onxONE\ng4sU6450p23bpBPu29eZ2AMBa4FOpj9kL/ueNG9xW2lXdQ6Wx56fYcgkdhIJ/ObAN0CGiUlfZ8Xe\noXb3VGGKgC+wsmLXTF/bb1sxU4UpEqEEff2jDmKfIBM25BqCQXtRlq5Lqt5zn9vhpOBU/hTJ9NXU\n6+amOP39NAlYtwnsdtAK2vf/YaQDXza8l+05Oafm/CxXxg9x/yMRGvjPSOy1fI3TTLB1UGYCTmI3\nDIPDpRNcuAjExKaw4n+K1L7wBfmpFLth2N77E0+wMBjBr/nt+IFF7B2sGK1FIG2WQ9h3H997+nuk\nIikqIfHp57IhS7E3GvDLv9y2HqhtQO20OAfUoG3A9DQju/v4/OdhLNVnxVtmS7M2sY+NMdIKoYfy\n5PNtN1MNbk5iB7kP//EfpP/wPeiGLqnEo6PWyszmaTmOeraD/fKfRqQMg4M2sR6dgbvvJqFXMfQQ\nrcQZ0gnbLMCZ0swSfx2WEnu9PILhsxfBtGcTRYJVsv42xT42Jutitm+Hyy5b+by6iG4QeydzcsnE\nVtO06zVN269p2v75Neyqshq4FbupGsN5u/NNTMhS5h07iFClWmpJzeahIe6aeS65nPD/pZfaO+P9\n1sufpEWAu76R5rF5SUVrV+xqfUUggLX8NRyJEwlELNug3CgzV5qTqVosRjyQplJzNDxNE9WuFHs0\najc8hd/9XXjzm8kkg8sqdqdzkYqkyFQzGIbBYmmBoQrS2BIJgiaxp7Q8k9t9yxeXvPJKUc/mAqnp\nwjTjifHlA2yYNTxAFHvTVuwTyQlra8CovwbFcTIh86R37LBtgakpWRi2DLGfzJ8kUhGSeOghxGM3\nib093bEVyGKY2TbHzLzzPROXsD0HLaPF6ZknecMFD5LO+igd/tUzEvvUCfHAd4zIdTmJfaowRalZ\n5hVHgKi8bsWDx8flBj34oAzYz32ufX3KZz98mIWxPncdHkXsnYKngSqtBelDB/ffRraa5b8OvRJi\noqTn6v2WYv+7v5NCml/7muNidu7EAD76MR8HDqxM7NFgS5S92d5G4iMU60WqzapbsScSjPyPj0I4\nz2K2rT5KJ8XugJoNjsZHXTONdmIf6JdO3oiUYGDArnFzfA6++10SZqmDWnypreRCG7GfLpxekhED\n7gVKAJXyMIavZrWrdmKPB2oUtDjNgbaB5eMfFyumPSe5h+jGkU4BjhUJbAWW6EDDMD5tGMYVhmFc\nMbLSNPEZwJmZkvAJuURiTaYKbawVChEN65IV88ADcNVVfOr/agwMSLnma66Rj4XD8Kbf3UqMErff\nOLdiRgyYx3bUNXAq5uNZqWq4I7UD4nH6tTSNirvYEldeKQ/+wQclJtCezXDBBfC1r5FpFmzFPjoq\nDaWtUBSIV1hv1cnVcixW0mLFDA5CMknYJPb+cInJSY3Tp90VDSxccYWoStOOmSpMuXZOUnApdt0M\nNjsUu7VHakxylMeDC3Dq5zhwzGwDu3bZil0R3TJWzKn8KfwlaWoPPQT099NCGH3JytNQUQaXWo15\nfw0/Pga2Xsh2U8ifmH2S17w4y//f3nnHx1Xdaf97Z0Yzo967ZDXLNsg2xhhj0zsO4Q0hWRKS0JOQ\nAilkU5d9390kmw2bRtomWdIgJLspm1AWSOhlDRgwYFxwb7JkW71LI2lm7vvH75577zR1aZB8n8/H\nH1mjKffMPfe5z3nOr5y8LMTgK1/GPU5FgcbDcjHXFwlpKRsAYHe7+OWXHHKBXz7A7NLkclmK9fOf\nl3OrNvO3bjXeYDdt+RKLHQjI03/8lMR/h4J6bBy7e5j+bgkLPbRXVlXv+vof8bp0/Bn9tCLK9/Bh\nawW6fbttMNXVHKKaf/jNSVxwoc7gsfK4xB4IQKpSqAaxq+e1DrTSOtBKcbrlSxfllIugiib26mq5\nqSWICIkgdtveQPC43KjUTVt57CMZcsGbxDqENNM2iD2QHifM045oxd4/McXe31cAae1m8mE0sWd4\nR9FH0+nMiNofcruj0qBnHzNB7K8C9Zqm1Wia5gWuAR6agfedMOyRKYv8baQwwqLaYfZ1xjYU8Ke5\nCQwDBw6wM/9s7r9fGpqnplrEXlMD/rUrOTflJZ58JYsdbTtI9aRSk1sT8V5xid3nI9tvbV4e6j4E\nYCr2PDoID2dFNrE56yxh1+eei7RhotA11EWON0/CvlWEgUHsdsWuLraW/hbaR7rFijEUu0+TFU16\n2iBlZTKGuP0HVNKW0QP2aN9RyrNiHbZIYjfMVZvHbt4QjGIfJ2m74cjZ/PbOj8pz7cSuNhTjKPbB\n0UE6hzoJdcsFuGUL6Nk5MVaMGXrq7WdgZADa2yX5xZWOq6ycSkXsrj5cy5bwpb8PEW5byZFdZ8T5\nEiw0Ngqxn2Rwgl2x7+6Q4z59KI90zSj0Zt9bbWgQwrrhBuOLShe/9Uc/krE3N9OerlGYXsidd8rC\n7e4nqgHiZ556AvT1GhuYLRL/vrhD5+RAJu50CbfUCwq59Va5j9x8s7ynGeZbXMx2r4T4dnYAz3w9\nsRUTNl5kWH/qeSqvw06IhemF4OulJ9qK8XrFdrrmmrjfrbl/k14YqdhbJCpLnVtlnQ/nyMWjzkHu\nyasByAnLNTiYOo4Vk58vE+XYMXRd51j/sZiIGLDFsWfKjUrHBWWbzf2rrkAXKa4U0lOEtNO8QRhN\npztj/Eqhs41pE7uu60HgNuAxYCfwR13Xx6/TOYOwWxEVvja6S07ilDWDcYk9NdPNUECD/n7+o/Ed\n+P3idICVEFdbC7hcXHzSUXb1lPHanmZOLjw5xoaIsGJstYPtUSkRxJ6eTpEuk7GpxRZnvW6dKDtd\nt9RdHHQHunn4M9/irruMB8rLobk5ZvNUXWxNvU10hwcsxZ6RgR+5UP2Zw6ZNH9dnLyqS+P5vfAO2\nbBFLJSNSset6FLEbccwqKkbXdUuxG0/679BVZKz8dwa7s2WlUFMjGcDd3aLYs7LiJic19UodlqEu\nkU8dHdA8XBBjxViKvY+Bb/0LvO99tKVDYUoOlJRQOSLseCQbWLaMD1zrhqxGNj//QfOztm6F//7v\nyI5ujUfkCz65TO4cEcTevpv0lHTKfQWUjUQpdhA/ZNOmyNTRH/9YbKf3vx+Adl+QbCr55jflz6cs\nkfMUN0HJE6CvvxP8fg67+vCHXBQOwKI+DT2tlVaK+Mtby3jkEfja1yRiVtdtofOaxo7sMwE468Je\nOHwO+VGlIsJhseDLUm12JtbmuVrF2iNJCtOE2Pt6x88JsCOuYi8sJNQiNy9F7JdeClkr7yVUIBaN\nWjXlfPhWOPdccjLkC/pF24XceWds4VQTmmaGPPYO9xIIBuISu6nYU23FpcpfpW9YVqaq65Sq9prp\nD8FIuplImEzMiOmj6/qjuq4v0XW9Ttf1b8zEeyZEU5M0XrC197LHujI6Spo3yOK8xRzsPijdemxI\nzfISMFrHvdVbzooV1lxSLRLPP19+X3aWLOl27OqLsWGMjwISKPaARexet1c8vLQ0yoKiQvY22erQ\nZGaKwQ8JFXsoHKKnJ0x3c7GZ6xGvZjdYxK72BkyP3eslTRPC8GUFTJv++usTtF+9/35IS2PwS5+j\nO9Ado9hHRoQwTI991GAzI469c6iTkdCIKHa3G3w+/CO9ZGUcQA+7xL5X3YIOHhQ7SjWDiIIKm+xp\nS2fVKnlsS1NBjGLPz4fiin4o3srAT38IL75IWxoUpopKyzrjXHKG4HA2sHQpKX43rnXfo+nwqfzr\nv0rwyrnnSiHC00+3cmUam10Uc5zMTD+Z3swYxb4kfwlaXj6LhuMQe1GRtWGpsHSpbOwYDUfa9EF8\n/YtNfaC6cZmbp7qO/24Jb8QzTF+gB669lsMFbhZ1hdGA8vYRRlOP8hYn8+kf1LJqlRQIXW5M3S1b\nrNXZ9pRVVKYcY9U5R6G/jNGOyHO7Z4/Eo6/NNa6zKCtmR6toN7tiL0ovAl8vA/2xoapjoXWgFQ0j\nyej66yXLbt06gm1C3OrcLl0Kiy+6lf4My+PO8mXhufFmeO458tKEUb+6+Vq+8pW4lbctlJQQPnqc\nN/e1xoxDQYU7ZvtsxF72qqnYo9sJZmZ6YCSDnrTJjX82MP8yT3/3O2m80NBgkru9HrcqHLM4bzHB\ncNBsm9Xc28xND95EMEdjCGGiAx3ZJq8o/O//Sp9pgMoVkizS0ZYWExGjPhciN0/xesnx55ibp4d6\nDlGVXSVqPz2dilEhhANHowpJqeVCAmLvGe6BPrn4VNa9IvbozVOlona0GTWuR9xihWgaaS4jPDDb\nUuzbtsm9UiV9mqishLPO4miXfIfRHru9SBRA+ojhOxuZpyrU0Xyd8WVnpRjlDjqsx9i/X0o8rF4d\nd/xNvU0wkkp/b4pp1bYMZMR47Kmp8IunnoW6pxg0bJm2dChUyvKii6jshaYcF1RVoes64TV3U794\nI3fcIf1PsrIk2XfXLomW6u6GxqMpVHIEvF7yUvPoDFjEvqdjD0sLlkJeHjVDcYg9EW6/HTweQhp0\njvbgDVhbVcNhGZB50963D/9Xjdw/T4A+L7ByJYeXlVHVAxQUUH58gNE1Qv7H29z8x3/I97J4sYiP\nW24Re//4cdg+vITl+nbKG2Tj+uDWSGJXAVGn+7ZK0SrDI1ZRUdvbDMVu89jz0/LB10tgwBtdGHVM\nqD4HbpeRFfvJT0JpKcFW+Y49NmcjKxCmzyhN3RXoiiDWvMxIH3vMVqulpfz6rTO4ZE0tDOSPuXnq\nHhkim27SU4cgb5+ZeRxN7NlLF4kVQyDmveYa84/YD8tmJCMjZppytGLH65U0ZzDtmD/v/DP3bLmH\nB1K2EMBPEDeHj3nHsrSpWGHsmvRWxFXsistjFHuUFVOdUy1/q6ujytjcbTweVW/kne8UebBiRdxj\nOdJzBHolqsDMuC4rg46OiFhnsOJqNzVJk4oKPctUwelGhUh3TiDC8RgZwbJ47CgooHlEZN6Eid1Q\n7Grz2lT6Rthmji7v19kp3wkul4Sj9vbG1O0xx997xOxlq/YeB8J+ggh72y9+5XkOGLZMWxoU5hjH\nfvHFlPdCc4EX3G5pq+Yd4vr3fIHXXhPF/vrr8PGPSzTJjh1C9jsP+VlEI/h8QuyGYg8EAxzqPsTS\nfCH22r4hcI3S1hlZGTMuFi2Cm26i67STCeth3ENyQjIyYDgoAwopYn/hBXyokg3D9PmAggIaU4ep\nWnkO3HEH5b1A7TM8XnQS27fB2rXy9JQUaz96YECsx109JTQEt+DP3Q6+bnZsjtzQf/VV4fKTRrdG\nbGjm+nPR0NjWIj6HXel6XB5SM4LoYReDccrpJELrYGtM1VSKiwl2RtYBAsgaDNHrtRS7GSUGFNii\nUc47T27ICbFoES+0LGZk2A3HTx1z85RAgHw6aKg+Di49woqxd53KyfaJFRMY64PnBvOP2A8dsiaa\nkfIeodiNEBmV+r+/U2LDNzVtwuv20qK1EMbNgfy1BINajGK3I3dZMSmuQeitYE2ZbCaqpCSwPMu6\nOmI99kCPWda0KtuoT33FFdQ+eB8AzcejLvx3vEOYriySPBVePPKiSeymYjdS/+3ZiWzfjmvLmxSn\nF/Nmi9z4TsbakMrwGMuM7AApKVJCZ9cu2df61rfg2mujytAXFHBUlwusPDNS1cUQe0DOh+YOMhSM\no9ivvVbeMiTE3tGByOMzzxRih4TE3tTbRPaIrJpU9NzAoItguiSE2Vcs6V6L2IMu6EqFglzj2Fet\nonzER7NR70pZdZ6QzurVUlRTVVTYsEEWiC+9BI0tfk7mLUuxG8S+r3MfOroQe2kpi4Z94OvhaFv8\nhugx+MlPaH/gPwEI98m8rqyE4aAMKBzWZGwvvICbMCmuUVOxD+Vm0jrQStXaS6GhQYgd6Klyc9LJ\nkXbW978vFS3/8R9l/2A46GE52+ls3Q/Vz/G3h/0RJXtefVUWT+7RQMTegNvlpqGogaHgEKmeVDK8\nkVmeOUYSUV+ccjqJ0DoQh9hLSghGrcbQdbL6Run1yOZHtGIvLLL2Caqr4xO7ef2uXcuWoLEKP74q\nxmMPheS5Xi8wNMRP+CT/cK0EEiSyYvKyvRBMo2toIsu12cX8I/bDh63lukHsMYo9JYXSzFJSPamm\nYt/UtIlLai8Bo+TAjvxzAcYkdi0/D19aE2m9NeYS9JOflI52ra0y+T0eI+/AHu7oz2ZgdIADXQdo\nH2zn1NJTjTfUqK+TpWtrW5z4OnubmChsPLKRjICEwLW2GiGKxvPtIXF85jNw/fWmHVMy7CUv3Zrw\nmcZFoeeKpLr2WvEuf/EL6SD4u99FZviTn89OTykcPntcxZ5m1KVxe3SGRoc43H0Yl+ayLpqqKjjl\nFAprxeIyl8pXXmmZ9arMaxSO9B4hJyiVKmprRcUODEAoQ94rrmJPgc6aEnTNZsW4XJS/5wZaPMOM\nhkYtYg/GD2S/+mrZ1tn+42f5J74KXkkSU8SuQh2XFiyFv/97yr72PfD30NY5HPf9YuDx0B4SFhzt\nzcPtNmqjheSEhnVDsW/cCIDPNSLE7oNGoz55VXYVVFZSYRB78+rYcr0XXig3qjvukJv5Fed0cxmP\n0d7eSNaG79HZqfFlw+kJhSTyds0aIpNEDNy86mYAhoJDEW0iAQpyZQUVk306BhITe+T+CX19ZAV0\neg07MZpYi40wxrT0XlWqPwJ79shWx3e/K4mJOxBid7WcFtHHGCKb9xAIcBmPs75B5kiEFeOPInag\npcOxYiYHXRfFftJJQgJjKHaX5qI2t5Z9Xfto6W/hYPdBzq8+n1Sjb+QOv4R7jUXsaBrB3GZSu6Q+\ne1eXJBBu3SrKbtMm2fP0+4mxYgAe3y9p5meUW6F0hTlpkDJIW9vkIgdeaHyBotCp5ni7urAlsdg2\nT5uaYOdOSlLlQmno9UakOGeniBwPZUeuldPS4KqrrLcwUVDAn459C/7zYTK9kWVdI4g9HCZ92AhP\nS9EJBANsa91GfV49Po+t8NEbb1Dyd1JR8nirsft8pVGBYvXqSIa2oam3ifQhIazycrEJBgYgaGQZ\nRhC7odgHU6Dti7cBkaUQyutPQ0fC3MYjdhCibSjtxENIFLvfUuwq1HFJ/hIoKKDs9IvA10NH1wSa\nqBpQRbWGurMoKjJa3I0ail3XcA0PmTH+foZl89QLh1PkHFblCLGXGyq5+ZSa2A8x4HLJzfx/HghT\nQgvt3ccoWXycW26BX/5Szmlrq0znxYuJS+zXnXJdwvcvypMNzMkSe3SpirjE3tFB5gj06nKtxdS4\nKRZftah6Pzk5cgwqsqmnR3JVGhtFxOwarmEEHy73MO6W1TE3qAhiNyZ6ZprYLr3DvYyGRukb6Yv4\n/JUr5T32bZ/9RhrjYX4Re3u7hIhVVUn4wxiKHaAmt4bD3Yd5uVmWUOsq1pGbKSSzI+10UlISJsPJ\nxw22E8g9QrhHECRgbQAAIABJREFUlMDvfy8n/AtfkH2+Z5+1OQc2Yld3/8f2P4bf42dl8cqI93Vn\ndNLdMfFY1yM9Rzjccxj/oBUK2dqKTbHbbmzHjkEoRInRxquhTYtIcc4wOHY0O3atrL4LO7GH8wo4\n2HkJDGfTGxXGpkqdpKYCg4OkI/ZDSorOUHCI7a3bY/cmNI2yQrn4j7Yab1BfL7XnjdC/RN+Bb6Sc\nlBRxb9LTJfM8mCYXkd2KSUuR72UgRTZOIbJ4mbKUmnubJ0TsQITVpqwYXdfZ3bGb8sxy05IozSwF\nfw/dPRPfPVS1Vwa60yguNppSj2jg8chNu8uIoMrOJo0hU7HvDEqCTX1ePaSnk5WeR8YwNJWNUysF\nzA4/7f2tFKQVcNFFch3t2GGFv5aXE5fYC9IK+JcL/oV/vzy2L3BpgdGlq3tiN7a+4b64EVcUF8cS\ne2cnWcMwSoih0SE6hjoibghnXrOIjLN+zhmf/7XZhFrdYH72MyH1666TdInf/0HmcsGiRxhtrYvu\nexLRR1lNdH96Nm7NTd9wn5n1aif29esBLRSzEZ0MzC9iVxun1dURxB5PsQNUZ1dzqPsQm49uxqW5\nWF26mtwMuejfGqw2ewAkwuajmyGrid7BYkIhWcKuXAnf/Ka1gReP2FW9j6cOPsWasjUxFSG9mb30\nGsXVv/QluPHGmPaqEXjhiNS1Ge0uJssQzS0tmMRupp0PDJjmZrGR/Xdy82iEYk9PEwIbzoyVVPGI\nfVt3JcPDov6jW3dGKPaBAZPYPR5Zpu7r3MeKotjN4MLMXPD1cLzdts9w//1WQkEUBkYGJBlktJCc\nHNkHNhV7ehzFbts8bTP6sNoJoCJLBtrcZyP20XGIyCbh8lLzCIaD9I/0s7t9t9gwBjK9mbhT++nv\nm/iltalpE1m+LLrbfRQVCZkMDwOpqYR0F65RY25VV3OJ+xn8lZvoTXPzesd2SjJKrIiOhgbK9Qya\nhydYsmPlStpHuilIK7BCSLdYVlxZGZGlU22449w7+OTpn4x5vKJQJmhT28Qk+/4u2QNTe2J//KOk\ndQSz8mJyFBSxgwQlhPVwxA3b64X6637KgO+gSezd3cLLd90liv0bRjD2D38I/pQg3vrfg+6O6HUD\nEfdxc6JrqalmgT21yspPs7Jcs7IgtWIvx95KvGKaK8wvYldVACeo2KtzqukZ7uGlppeoza0lLSWN\ngmy56Hfvjg0tjsarza9CVhMhPYXGRvHU3/lOmWj/8A9CMGefjYRRqFAVr5c1ZWvI8efQP9LPuvLY\nNOq0nAEGe9J46inZsLz3XvjP/0x8HBsbN5Kekk7H8VRONez6SGI3Jr+txnTJcSmk1HAkEEHsNzZs\npvji6+n3RUkU5Gl+v0XsoRD89U1rUynCoiGK2Pv78ROgMHOI7MJ+nj/8PDo6K4pjiT03NRdSO2mL\nt88QByo5yTWca16wGRmGx54mCtHjQcJfKypIPSrnYiAF2ox2ffbMSqUOp6TYvV5zTI/sfYTdHbtl\n49SApmmkZY4y2J8S711iEAwHeWjPQ7yz/p20trpMxT4yAqSlEdZduIMGm1VV8YvRGyhYczd9WT5e\nP/Y6q0tt4aEPPUT5ktNiS2kkwooVtLuGKPDnU1Mj6RRbtoyv2MfCoiI5QUfaJraBqPbAFLG///2S\n7Nw5mhkTymondnVDiLZwCtIKaB9sjyD23/xGrpcvf1k2ps8+Wyyp798FfYvkfQ5ujPzOoj12AFJT\nyfRl0jfSZ4ZRL8peFPG6vCU76dy71AyFThbmF7FPVrEbYYbPH36ekwpkU67Q6Ps5PGz1Gk6EV46+\nQkWOKOCH/ztAMGgp9BtuEKJbuhTJaLrzTvmDz0dFVgUvffgl3ln/zrh+ZGZOgOHeTL7wBYmoWbtW\n7J1Eqn1j40bWFp1PZ6dmNnuyE3sorIliV8TudnPxGz28q+IiVh8jwoqpKRumsuY+euLE2mqafCeK\nwE8/Hb7y7XyzCfeYxN7biwbs+vFT/P2nMsylajzFnuvPlbr0nROzKxSxh4eyzAvWVOypohA9HiTB\nqbkZ1463SMPLgBfajVondmLPT83H5/ZNTrHb1uaX1l1KfV49n/nbZ+gOdLOqZFXEUzOzdEYGJpZ+\nuLFxI+2D7Vy17D20tGBZMcOg+2UPxa7YCYfJDOi0ZnvY2baT1SU2Ys/JoTxnkRmNNB705ctpTYOi\nEQ8ulwQBKMXuchnBZ/bSqRNAXYkQbXPbxMJiFLHX5daZxU0B+oY8BI29Es9jj0j5hc2byRwRC0V1\nb4quNhpN7B0dIp5OPx0uuEAee+QRmcs3fTxMT768T9PWyMb1cYndL8lpfSN9HO4RLjIj3gyUNRwg\nPJxmr3idFMwvYj90yGoQPEHFDtKFXBF7Uba1ATgWseu6zstNL7PGsCfu/rlMKHs0XlkZIpf7+qwQ\nD2PZuqxgGQ9/8OEYfx0gJy9IsLeQLVtkI+vaa4WT4xW97An0sK11GyvSZMOxoUFuYmMq9rPO4uQn\n3+TBjzxF2iiR9aHz88ke0egJxQ80rqgQy2VwUCIjLrhkED7wf9AIj03shszLW1rITaddS44/h1RP\nKrW5sbvTSrF3dVrTb2CAhCrnSK94QCMD6XGIXfxkt0s364vT0UEWPrr9cDzcS64/N8IO0zSNssyy\nqVkxPh8uzcVnzvgMrQOtXFZ3GTetuiniqTnZGsGhtAkl6Ty0+yF8bh9nFm1geDiS2MOpQmwmsVcJ\niWT2BnixYIiQHopU7IiCVf1px0P3smqCbigyYu5XrZLUkKYmybg3S2VMgtgXl4pt19JprQjH2kjd\n37mf4vRiMn2Z3Hef9Xhfn3VuPd/6hqTQ/vSnZK07z3wdxDagzk/NjyD2e++V3Lcvf9lKaM7Kkn8t\n/S3g78brGqApymaMt3mK329aMYe7D+NxeWLi3xevOQRaiIcfHuNLmgPML2L/4Aflzg1C7J2dEA7H\nzTwFi9hBiBagNNcKaxpr4/Rwz2HaBtu4ZEU+y9nG9r0+SvOtbE0TEdW8mFDrq/zCMAT96Lqke6vI\nHFULy45NTZsI62EaciSyJjtblFTE5qlS7Cp19Cc/ka3/j3xEXrDSdnO59Vay151Hz0j8q62iQi5s\nVUn33P9zBBa9RG5a14SInbIy0r3p/OuF/8on1nxCsgmjkJeaB2kd9HbL3TgYFGvlwx+O/32ZdWL6\nvTHEHko1rJiRwQhirw5lcCjPxYHew3FvLuVZ5ZFWzCQ8doCPnvZRfn3lr/nT1X+K2UPJz/WA7qav\nb3xm39i4kfWV6xnslnHYPXaT2EcMxaiIPaDTbbRoM0NpDRSkFTAwOmAWYRsLbYvEHy46JnNh1SrZ\nkH7uOavc/6StmPxicA/T1iXHvGuX6ApVDjsa+7r2UZcn0SyqtzwYxJ5mrMZyDTE2MEDh9R8HYGur\nVMaMZ8V0B7rJyJLz+vDDcpmowCs7jvUfAw0K3U00HY8MZhjTihkWxV6ZVRkzv4sLPbirX+CBB+KP\nd64wv4h9/XqpJQFC7OEw9PREptTbFHteap4ZrXBSoSj20hzLlhiL2F9pfgWAM868mhvXSibS6Tl7\nY8uYjIxE/p4yvrdaXGh97Q0NYxP7xsaNuDU3teliaaSni6qLVuymFZOSAiefLCz585+LyWjPZs3J\nIbu0JqLDkx0VFcLRe6X/Np58WXKW+1snRuxGOusnTv8E373su3E/I9uXLR77kVzOOcfKeP3Nb+I+\nnSM9RyhIK6Cn2xWr2P0GsQ/2RhB7bSCN/XkaB7oOxCX26pxqDnQdmDKxe91eblx1I5m+2AiU4ny5\nuTe39XPrrQkyepFmyG8cf4N15evMpDO7xx7yK8UeEPlsfLdVRnz2xbUXx1gBajNP9bodC60hIfSi\ng7IncZ6IYQ4etOXJTZLYPS4Pmm+ALmPz/oUXZEVt1jeKguouBrIgVxV1e3shqG7aBOVC+cEPqDvz\nCsDY/yJWsavfdZ9Ygd3dEnQVL0hCNbEu9RyjqSO2exKModh7DkuYaRRy/DmElvyFbduIsJbmGvOL\n2O1QzY47OiIbShslBUCW3Eq1KyumIs/axR6L2F9uehmf28fKqrV86MH34dcCnJv2WuwT7cSekjKh\nYvplxXKwKd4wixdbLVnjTYSNRzayqmQV+ohc5BkZkhnZ3o4Vx65rlhVTUhK/O70N9pIH0aioEAWt\nFNZolpSFrXYdH5vYm5tFbk7gxuZ2ufFliBW0cSN88Yvy+Kmnxn9+U18TlVmVdHcTQez9/Raxuwf7\nzM47dHRQ1+ehMTPEoe5DZnkJO5blL+NI7xGrj+rIOLtdw8NybscKozJQki833B0HO/j5z2XxFA9v\nHH+DYDjIuopYYh8dhaBPzrl7JCA7m8ac//dHofXsh3jiuidiE4QMYlMhlGPBLJe7SzYC6+rMRcGU\nFTtAStogPcaCUBF6Y2Ps84ZGh2jqbWJx7mIzRUVpkL4+CPoNK6a/W6IWPv1p0r3plGaUMjA6QJYv\nKzJHAmv8w5428zJIVDBV9Tqt9nVwpEdWBfffD3/4Q1RUTCAg15TXa3ns3YdjbqpgNCNf9gCapvO5\nzyW2F2cbC4LYEyl2gJqcGkozSs0QxMp8W9jbWIr96CusLl1NijuFkhLYd+6H+XTKT2OfaCf2CXYg\nrywVQq6sGSQlRYixrCxWsY+GRnm56WXOqjzLFKPpRkvFzk4gJQXd5SasuyzFHt19KQ6y/dn0j/QT\nCseqVPWdPPWUcEmnaw9ZIQ81oaa44Y4ul/F1Hz1KrE+VGP4U+a4uv9x6zJ7SbseRniOU+msIBIi1\nYnxCop7BnkjF3g1hDUbDo3EVu1rBqfKz4xL7JAiuskhI4rHHQ4yOyp5uRxwBrWr5nFFxRgSxq48J\nGAlhLkXsxl6JPwiFDfFLL0yF2It2HYGBATRNQgJh6oodwJ8+Qn+fsOqWLfJYPGK3hzp2dsp9WVWi\nFGI3FPvooHXisSJoYpKasMbfGWg3Q4NVCYpoHOg6gNftZXFaH0eHcunultr1n/mM5b6Yit3vB00j\n05tJx2AHR/uOJib23MP8050dPPSQLJzjNrKZZcx/Yu/sTLh5CvC1C77GPe++x/xdRcWkpAbMEx+N\nYDjIa0dfY235WvOx8mWZpDTGkdRTIPbqMlFiZXVW+Tl7vwmFN46/wVBwiLMXnR1B7Oa+saahpxmq\nTin2iRC7kRmrUqPtWLdOxMlrr8kxNfUdoTKcScXwfvr6rKqFX/2qxPWnphoLhKNHE9a5iYeqyx5g\n1Se/w8MPiwVz7bW24mY2hMIh9nbupdInV7yd2AcHYdRQtZ6BSCumrsUiauXh2qFWcNtapZjVhIh9\ngud3UbF8v88+Zk2wF1+Mfd6mpk1U51RTklFijr2w0PqYIa+8TzSxm35cHEyF2AsGkbsPVr9l8x49\nPDzhcSukZ4QY7PcSDo9N7Oqm2lDUYEYyq+2gCGInKHtFBkxiT09M7PYN1ETEvrdzL3W5dSzKHyKk\nu/na18S6aWmx+ribHruxOs72Z0uvAfS4VowSkO+67ghf+5rM7f/7f+N//mxi3hF7T49kgEZbMYkU\n+6qSVVxad6n5e2qqKInU/PaEjsX21u0MBYciSgFQVSX+hyIPBTuxT1DZLKnKBi1IUZ0Vdx6P2Dc2\nSn2QsxadZboMGRmWYg+HIZQmy1Vz8zROk4poqMkXz2cvKopsOLKvcx81KUWUDYrp3tIiUadf/apc\nrGZ9qObmSRF7YYGLtNPuR9MkG3D5ciFqNU6Fg90HCQQDLPLJGt1O7LoOfWHDiumPUuxHraifeIq9\nLq8Ot+aeHLFP8PyetToPUjvYt7WQujp5mVHqJQKvHXvNLC7X0iJT2uOxeDSQYpzb4SEhdo9HwjkW\nL05ot02W2HO92XhDmF0pLr9cQnkvuQT5gqeg2AtKhgl2VLB73zB9fXI5NjbCk09aRA9S092tuVma\nv9QkdqXYe3shaKzG3IQmrdgnQux7OvawJH8JlcVyDd91l2UFPfqo/IxQ7MA1y60uUPEUu7114D/+\noxTX+8EPYuf1bGPeEfs998AHPgDHg8amiWHFJFLs0VBE5M4+lvA5auPUrthNI1zF0itMQbHXlhbA\nzeewZMMT5mN1dcKNAVt4+bOHnqU2t5ayzLIYxR4Oy+QPGwk6Li0sMn4C/WRVyQN7swg73v1u+VlV\nHWJX+y5W5CyhEInFbG0Vpa5C+drbke+8tXVSxG4vpAWWADUrVxpQDR2KPRLVZE9QAugNGlbMQI91\n9Rw/Tum+Fvy6B4/LQ2VWbFyr1+1lcd5is/zsTBJ7RWEm3g0i0y66SIpp/e//Rj6nf6SfA10HWFkk\nElXFsINNsacYVszwkDXg0tKEhdLASnGfKLEXZZbIJrxB7JmZco2Vl2MZxJMk9qUNQ9BTxQN/lRXh\nBRdIpNXVV0sJZFX5cXvbdpbkL8Hn8ZnEXlsrc7yvD0JqNUYwgtjVnkm8dn5q87htoG1MYg/rYfZ3\n7qc+rz7Ckv3VryQ35YUXbEMPBExiP7nwZB6/9nHOKD8jJiIJIrOaNU3abg4MSAnoucS8I3a1pOvV\nRc3o3YmjYuLB7ZaysqHMOGtDA680v0Jeal6k0lPErmagwhSI3ev2UtnQTPPwHvOxFSuELC+7TMYY\nCAZ46uBTbKjbAFicpTx2MFS7ERLnHh4Stp8AsZu1UhJkKF51lXxP+VVHCYaDLC9bRRGybG9tldjg\niLakKsxyEh57rj83oiF0QmI3moXkapImbFfsAD3DcsF5+rstxd7SgisUpsZbRHVOddyQSxCfXSVS\neYZH4z7HxCQSdTRNo/K8J1nxgd/zqU9JtMmrr0aWslU3LJXFaid29TGDXhmsqdgB/vxn+M53En62\nx+Uh1587IWJvG2yTqooNDZK0EI2oSKCJQpUn+MVPU0lLk33PUEhsjuZmW4Pt1u00FEmFRXuKSlaW\nYcUkIPaxFLvfI03BG3saycmR+2E81+pIzxGGQ8PU59dTVSvz47KLRlmzRipoK2RnE9n/Ebik7hI2\nfWRTZAEyA6oCqgrRPessEW333jv+9zaTmHfEriIz+gMeSbnukavF40GYMRQaNzJjyTlbGK27P+7f\ndF3nmUPPcGblmZERBypcYAaIHaRA2cHug+bv7363dAR7803xOR96fRODo4NcXi+7iwMD8vYeTySx\nqzhu15BBagWxKiYaldmiYFW7uWjU1krJhapzxT9YseQck9i3b5fM/U98wvYCWwz7RJGXmkdXoAvd\nkP6JiP2ttreozKpkdEAu8hhiHzAKRdmJ3cA11VfwgeUfSHgMywutAmUz6bEDlGeXknvpT1m+XM5n\nMCjx4QrKAlKZuXEVe5Y84O5qt4i9oWHcG2hBWsHEwh1VudwNG+D5561m4gpTJPYzT5eTc2B3Ouee\nG6mYL79cooS6+4fY37nfPAeHDol20jQZam8vBFOETKOJvT6/nrSUtLh7J2BksXbt5x3vkDpM8Vyr\nPR0iqpbkLyG3Kos91PPIv8tq/F/+RYIHtmwxnE2bYh8PXreX4vRik9g1Taytp5+OXezPJuYtsQ8M\nANnZBLtFyrrdRDUhTYwbv/4kQ/W/Y3A0Nvtyd8duDnQd4PLFl0f+oaREJvhYVswkLoCanBoOdlnE\nrmlS6/3RR8Vr/85dw/g9fi6okTzogQGLzGzbC5ZiHzIk/QQUe3F6MR6Xx8zojIe6OtjZuQ2Py8PS\nk86mwC1hgSqJpLpaVOhzz2FlM03GivHnMhIaYSgoMZOK1KI3UHe07aChqMGsrR1D7MY2gbu3K4bY\n/98V3+ZrF3wt4TFsWLzB/H/KSGjs8IVJes2lGaVmav+ZZ4rge8Jy3tjeup20lDRqcmUl0toaS+yB\nLMnidA0PWsQ+Aai0+vFgEvttt8mHfvvbkU+YIrGvrC2GDLE6L75YGkWBhLPeequo8d8+1IyOblb/\nfOstqytkZqah2L2GzRa1eZrly2LPbXu4+dSb435+bW4tB7oO8LGPWfmM0djbKXtG9Xn1UFhIPftw\nd4rdmJ4u9etPOcV4sm3zdCKoyKowiR2s1JtEeRqzgXlL7P39QFYWoR4hNI+HCRO7SgNWCQp2PLLn\nEQDeueSdkX9wuWSGRhO7PfN0EoquNreW5r5mAsHImi1nnil7Y7t2uTi/+nyzBG1/v2WzRih2lcQy\naBD7BBS72+WmPLN8TGIHUZVL85fi9abiXVRCTsqAGS1QUSHe8bnnIolQ5eWiJicI5UXu7ZALTN2P\n7Io9GA6yq30XDYUNJoEnInZPn0HsKo+gpISEYU8G1leuN//vCRObRWzHJIm9LLOMY33H0HUdvx/O\nOQf+9jdrD2Vb6zYaChtwaS6GhoTIVGMwU7FnypfiIjzjxB4MB+kYNMreFhXJDvbvfhd5c5siseel\n5qGVSmaoIna3WzZkL7xQzt1f7pdQWxURc+CA1UTetGISKHaQzGGPK37p67rcOhp7GhkNJT6fezr2\nkJaSJtaJmnzxanpAxObpRBBN7FVVMu577x27iutMYlrErmna1Zqm7dA0Laxp2pqZOqhECIWskqID\nA0BWFsFeUd1uN9ZEHIfYVUcflaBgx6P7HmV50fKYqm3ywtKICorA1K2YHFFqh7tj12eL68P0HS1l\nVbFVXMqu2BWxd3RA2C/EbxL7BBQ7iB2TyIpR2Nqy1arOWF1NkbvDvLGaG06bN8s68/bbJ0UAZ1ae\nCVglib1eqVV29KgV872jdQeBYIDVpavp7saM+Yc4xN7TIXc/ZVOoJp9jwKW5yE+V5U/IhVXoKx4m\nWQyrLLOMgdEBM6T0/e+XDj6VlbBypc5rr7ojbBiI9diHjGNzEbbu6hNAflr+uMS+vXU7Orq1j7R6\ntdx17PM7oij5xKFpGrnLN5FbfZgVK+Se9PTTUhHV7xcP+5WnS0lxyQb2k0/K61SoZYwV42bM7mLR\nqMurI6SHzAqM8fDasdc4pfgUsVvHI/ZpKnYQS2j/fmtTdrYxXcW+HXgP8PwMHMu4aGmxOqIoK2Yq\nil3Vr45W7MPBYV5ofIFLay+N97KZJXZjCW732RWKq7qgYzFL8042H0uk2E0rZsBI9ZuAYgeozKoc\nU7Hv69xHY08jZ1YIAVNVRVFYxp6SYrt/PPigqOSPfnRCn6tQnVNNWWaZGdIJotT+4z/Ek+3sJKJB\niso6VX5pQitG7YVE7O4mxp/f92fqXYXUdRJbHsKOSXrsSjwoO+bmmyXcb8MGONQYpOevn+PCmguB\nWGI3FbvRqHnSij1VFLs+hjx8dK/E8122+DJ5QH1v9hVpRPrl5HDSFU+w6p9vMhdQ555ruSlr18JA\nZxZLM9bgcXl48klx8VSwj2nFGFmlnpyMcbOp7VA3K5UAFY3R0Cibj25mXYVRUnsWFHtXoIuBEcsa\nfM975Pq9554Jv820MC1i13V9p67ru8d/5szAntKurJgIxa6IfRyFoS664/3HIx5/s+VNhkPDppqM\nfeEYxH7bbXDTTbGvSQCl2O0+u4Kv+DCE/OQMW8W77IpdhTN3dNismIE+mTkTnICVWZU09TYR1uP7\nyo/tewyAd9QbIQLV1RSOyHKpvNxWOUFN+nFsj2homsbZi842FTtYX2VXl9Qxe27Xm3jufpNNf62h\ntTVyNa6+i95eIT6tx9g8rasTEli+nIngvOrz2FP0dbKHGZ/YJ6nYwRIPI6ERTlp7lPvug5OvfBT2\nb6BmWHoRJiT2oAgUN6FJEXtRehGBYMBsuhwPj+x9hNNKT7OqE8aL+pqiFQOY1TPjQY2zOkXyRJ5+\nWsJCFXdbxG4odqOHwkShwiFVad9obG3ZSiAYsIg9LU3+jaXYJ0nsQIRqT0+XcM8//lHyNWYbc+ax\na5p2i6ZpmzVN29yW6AscB3ZiV1ZMqE++pcko9vy0fDwuT4wVo1K8zRMejdJSuaPYsw3U5P/Up+TM\nTRClmaX43L64ky+YK6Fw4XaryMXAQORq3CxuaVgx7oHeCat1ECtmJDRidoKJxmP7H6M2t9YMLaOy\n0oyMiSjFME546Vg4q/IsGnsa2doifuwf/iALgMsvl6SO//n2lQSPruTOOzUef9xKnIJIxe5xhWT3\ncWhIuqc8/7xUtpwoFHHNILGrVaFS7N976Xss/uFiGnsa2VN7O57UQX70PTl3asNYeeymFWPU4pms\nYl+SL+29drbvjPv3jsEONjVt4p31tn0ktcMZT7FPgdgrsio40nMkbtmKjDxRsmXaqQwOCp+ebC1O\nTY89ZCh2V87kRIO6tlRp32jEvc4LC+MTe1NTTLjjeIhH7CB2TF+f1IOfbYxL7JqmPalp2vY4/+IU\nwkwMXdfv1nV9ja7rawon6ANHI0axZ2fHV+zjEI1Lc1GSUWIS+9DoEN958Ts8vv9xKrMqY/svKqh0\nfbtqn+Lkd2kulhUs443jsfHDXeky8Y4csJRKf79FZiB2TIRi7++dsL8OmEk78eyY4eAwTx982oyh\nB6Cw0CT2iDr20yD2K5ZcQYY3g9N/fjpP7H+Cc86Bd71Lws10wvS9eSm5Jd1s2yYXxI03Wq9VN7nB\nQfC4dasefnq6tMiZhMIyJfIMe+xghTU+eeBJhoJDXHrfpXRxkHd/qIU//lE2DQ8dkvmrppep2KdI\n7Co2/K22t+L+/ZlDzxDWw9ZqDOR7KyycMcV+asmpDAWH4t5c+jzSXCMvvMzkUvvUzcwUkTwU9uEm\niJabE/MeY8GluViSv4THDzzOSCj2Zr2peROlGaWRiWvxiH33bpnsLS1TUuzPHX4u4vFzzhGP/e/+\nbuJjmSrGJXZd1y/WdX15nH8Pzv7hRaKpSSZ9WppNsffL7J+MYgdjqdgrS8U/7/wzX3jiCzyy95HE\nah1mlNgBLqy5kI2NGxkaHeLlppfZ8NsNtA60cnD0FTxpfRFhxXYrBmxlBXxGl52erskRuxHLHm+D\n6YUjLzAwOhARDkhhoZl9OlOKvTa3ll237qIko4R/e+HfzMdPPRV++8wmeO81/OCPW/B4xCk45xzr\ntT6fZQf/Ogv5AAAZk0lEQVRFFFxMn9yyHZi4Yp+E15zly+KqZVfx7Re/zYO7HjRV4u6O3Vxadynf\n/+dqPB5JY9+1C7P0ACQg9klsntbk1OD3+M0kqGg8c/AZMrwZnFZ6WuQfqqpmjNhV1rbK4rajTZPj\nShupkcxlYokdoGvAGzciZiL46vlfZWvLVq7+09X8bPPPIv72SvMrrC1fG5mnEo/YO22Z2ZMg9trc\nWq5YcgVff/7rEZ+taRL1NontgiljXoU71taK26H6XZKVRdDoizgZxQ6yeac2Lp8++DRet0zesxed\nnfhFqg7LcZs3P43Jf0ntJQyHhnnu8HN89H8+ymP7H+MrT36FXe07ya/oYI+VmBqxeQpWITDTiuls\nnZQVsyR/CS7NxZvHYwtl/23f30hxpZgx9AAUFMy4FQMStvaRUz/CUwefithvaA3tgxV/YN3J5dx1\nF3z/+5EVkTXN2ozzpNiulNkk9kme4/uuuo/lRcv50F8+xMDoALevu53a3Fq+f9n3KS/X2LABHn9c\niN2+1ztdxe52uVlWsMzM2o3Gs4ef5exFZ8c0CKG6esasmPr8erJ92XGJ/WhI5lywN9/kUvvUVds1\nXT2uKRP7VSddxefXf56/7fsbn3jkE6bl2Dfcx56OPbE3tXjEbg9/3Rnf1ooHl+bi/vffz/qK9Xx/\n0/fNTexAMMCmpk0TaoIyXUw33PEqTdOagPXAI5qmPTYzhxUfH/+41CnJyLCsmNAUib0ut45D3YcI\nhUM8dfAprlhyBVs+toWPnfaxxC+aYcV+btW5pLhSuOV/bmFb6zaWFSzjV1t+xWh4lNUrMsZU7NnZ\n4i+HvIZiH+yflGLP8GawomgFm5o38eUnv8z3Xvqe+bfH9j/G2YvONpuUAFBYSDGyyzeTxA5w46ob\n0dC4Z8s95mMHuw6iobEoexG33Ra/A45K1PKk2KbxJJStiWhiP3BAwnP+/GerXsoUiD3dm86/Xfxv\nDIyKp/y59Z9j/6f3myWD166VEMg9eyKjM6M9djehiL61E0FDYUNcK6Z1oJW32t7i/KrzY1+kiF1F\n00wx3BGE3NaWr41L7EcGDuBO76K1VUtoxYAIZo/XLf7cFPDtS7/Ng9eIsaAsoTdb5KYS3VIwLrGr\n+VBaCp///KQ+2+PycOOqG9ndsZstx6Xy2evHXmf9L9fzxIEnxnn19DHdqJj7dV2v0HXdp+t6sa7r\nl83UgY0FVYubrKzITuaTIPba3FqC4SDPHnqWxp5GLqq5iFNKTokp3B+B/Hx57xki9nRvOudVn0dz\nXzOfPeOzPPyBhzmp4CR+e9VvOevUApqaZJwjI1b7OIXUVPEhw0bDYzehSSl2kM2jF4+8yHdf+i73\nvinFLI72HWVry1Yuq4s6lVlZnOV5hW9d8GhELQ17Y5OpojK7kpXFK9l8bLP52IHuA5RnlY95PhSx\nu72u2DjIyUAdvyKyD39YVMTf/Z0U8fnVryT8ZgrjvKzuMtZVrKMut870XhVU/9zR0Uhij1HsX/zC\n+J3Xo9BQ2MCR3iMxkTEP7JKebedXnx/7oqoqmVQqTGca4Y4gdszWlq0xGd6Hug/hz+mlpYUxib2r\nCzyZqVMmdrDKM+9sE2J//Zhk2MUl9qGhyOxlNf4HHjAy8SaH9570XlJcKXz+ic/zh+1/4I1jb8T/\n7FnAvLJiFFT3HLFiJPtsKood4BdvSHsbFVM8JjRN7Jh4xD5F1frbq37Lntv2cNeGu6jLq+OtW9/i\n6oarzaX5nj2RBcAUUlNlHoaMtGsXYZGAk8D6ivX0j/SbGZ7BcJDfbv0tIBubEdA0Ugpz+ELtXyID\nBGZAsYMs3VUWKohiVyGhiWAqdo9mxdBNhdgVcY2MiMf87LPwla9IST5dF6JPSZnSrpemaTx0jXQ7\nisYaW0rfmMR+5hj7PgmgUvUVmQA8vv9xPvO3z7CuYp1ZLjgCKixHZYhNQ7QAnFF+BiE9FHEMIMSe\nnRegtVWI3eOJqBhgzq/+flvV1imiMruStJQ0U7G/fux1itOLzaglE/Fi2ac5/vy0fK5beR3PHHyG\na++/lucOP0dhWqFZhG82MS+J3fTYbVbMVBQ7wF92/oXSjFKW5k8soSUmln1kZMIt0+KhOKM4bjEj\nO7HbS/Yq+P2i4kdcsqnjIiz1UScB+0bxSGiE3e27+dErP+KC6gvMyIoImD35bLA1D58OluQt4WD3\nQbMH6cHug2YSVyJYxI4VrjddK+a+++T/t9wiZS63b5eKUAcOWE1BJ4nC9MK4Y8nLs9q22T129XWq\n8gMT6LYYg/Oqz8Pr9vLArgd435/eR/2P6rnst5dRlV3FQ9c8FL/ipZpgSklMk9hOL5clid2O6R/p\np32wnYLCsKnYCwoiNxQVsff1TZ/YXZqLpflL2dW+CxBij6uYZ4HYAX555S958vonCYaD/GXnXzi1\n9NSYdoazgXlJ7HYrJkKxT0I9V2RVkOJKYSQ0wkW1F038yy4pid08naYVEQ+ql8Lu3UQ02VBQk1+V\ndnXfcN2kt9vr8+s5rfQ0bl4lxZS+8b/foKm3ic+u+2z8FyTaYJohxR4MBznUfYjh4DDNvc3jKnbl\nPHk8WFbFdKyYF1+UAPoLLrASdjweKfSRF1uidSZw5pmSdaluUmC217QU+xSu0ixfFhfXXsxPNv+E\nP731J2pyarjzojt542NvxO08BFgTTCmJaRJbSUYJi7IX8cpRi9gPdR8CoKzUTUuL6ITorSEVgDIT\nih2kPPPO9p38+JUfs611W/zV+SwRO0i+RqonlZAeYnXJ7NswME+J3dw8nYbH7na5zUbXF1ZPwIZR\nyMuLbM45Ax5zPKSmigjdvTuxYgcYqJPsVNe7J+9DujQXm2/ZzA/e8QMA/mv7f1GVXRWZuGJHPMU+\nU8SeJ7Vd93TsobGnER19wlZMMIil2KdC7DU1siP8zW8Ki/7sZ+O/Zobwne/IgiAaPp+VoTjFxSDv\nWfYeRkIj1OfV8+iHHuVLZ3+J1JQxEm3UdzdDxA5ix2xs3Mj7//v9PH3waZPYq8tT6euT3gPRxD6T\nVgyIz97Y08in//pp3rX0Xdy+7vbYJ80isfs8Ps6tEo9+Lvx1mKfEbir27Oz4HvsET4SyYybkryvk\n5mLWkIVZU+wgy/PxFPvAoKj0qV78IBEyqs3XzafenLAxxWwqdpUtubdjr5mNO1ErpqcHqbGalTXp\n6BFAXrdjhwSVP/MMLFky+feYIgoL49cr8/mmp9gBrlx2JeWZ5Xzzom8mrIQYgVkg9rXla2nqbeKP\nO/7IrY/eamaDLlkkMY3btycmdpjevFY4pVjq77572bv5r/f+V/z5PYvEDlaJ6Lh7G7OAGbgfzj3M\nzdOMjCkrdhBCHw4Nx21KmxA5OfLhwaB86CwT+69/bXXeiavYjWtwqhe/QkNRA409jdy0aox6N4WF\nslpRYwf5zqfia0ehIK2AbF82ezv30jbYZmbmjoUIYr/uOomemETqdwSysuCzCSyoJMDrnZ7HDvKd\nNn2uafwnKkR77NMId1RQdZfWVaxjU9MmfvjKD/F7/JxxqhD76GhiKwZmRrFfseQKXvrwS6wtX4tL\nS/BlZmbKOGeJ2D95+idZV7FuXLEyU5iXij0jQ5apustN0C+xUW431pUwwfCsL571RZ654ZnJfbhK\nllBlBWeZ2Pv7rX6ZNbY5YSr2GSL2z57xWb576XfNjNS4UKa2ipqAGVPsmqZRn1/P5qObuWfLPWxY\nvEGaQIwBRezhMPIFTEWtv00xE4p90kjksU/j/K6vWM8zNzzDczc+x5mVZ3Kg6wD1efWsX6+ZBSWj\no3Tt9+aZIHZN01hXsS4xqcuT5EDsc3sGid3r9o6d1T7DmJfErjrUDw1BKEPipDweLO97lja6AIs8\n1GfNMrGD5MkUFkYqG6VqpuvDKlxSdwm3r4/jPdoRb7k6Q8QO8MHlH+Tl5pdp7mvmI6eOX8TLvuG4\n0JAUYo9nxaSkTOsANE3j/Orz8bq9PHfjc7x484v86eo/oWnS2Nr+cQozrdgnjMzM+AX+Zun6nk3M\nS2JXwqK/H4IFkubvdiN3W5dr0iVkJwWl2JXPPovErqzeAwdiq9DOtGKfEJS0miVi/+y6z/KptZ9i\nRdGK2Dj6ODhRiH0mfOYJweuVD7OHO87g3Pa4PKyvXM/SAlEst98uxH3VVZHPc7msRfecErsZlWFg\nBlYsycK89dhBSC1UXAa7jAnQ2SmKejZZbg6JvaLCSkSK7jpnjxyAObr4FZPaiyPNILFrmsYP3/FD\ndF2fUPjpQib26YY7TgmaZotMYFbnNkjhs0TdCP1+sfjnnNjVhhZYK5a5qNo1w5iXit2+xxMskvKo\n7vCoEM5s2jAwp1aMy2Wp9mjFrparyuqfE1GhvttZDvecaE7BVPdJ5wN8Pqtb2JwRO9iy/5h1Yh8L\n6twmXbHPQxsG5imx2/d4QkWSGuxpPy7EPtsyLp5in0VWVT57IsWuXJFJFP+bOtRNbZYUuwML9v3/\nOSV2u2KfZA36mYRD7NPDvCR2uxVjeuxHj4jHPtuKfQ6tGBBCd7liiV0pdtV9Z06IPT1dSNyu2Gf5\nxnaiwr4amXNinyWPfTJQ8zvpm6cOsc8d1EkPBCCULyFxnqONc2PFpKfLbJsDKwbg05+WnJnoSL6k\nKHZNkwN5Gyn2t96S7u8LDWlp1v/nbPMU5tRjHwtqfs/p2BeQYp+Xm6f2TmahLGE8d9PhuSF2TRPV\nPkeKPScnfsXQpCh2iF9SIYnErjrbLzQkTbFnZESKlimW7J0ukmrF6Lpc5/OY2OelYrcTezAsQ3Af\n2i81s2eb2GFOiT0R1MTv6JDJP2fX39tMsS9UJNWKeRsp9jkn9nDYSnR0iH1uoUgsELAiBzzbjJrP\ncxEDl5trqZpZKgI2HlQUlq6LWp+ziCy7Ytd1OQEOsc847FaM47HPEewJMuAQ+1wjQrEbncvcx42a\nGCeIYtc0S9XMmQ0DVhdtmHRtHgcTh6PY5WdSiF3FsjvEPrdQd/PhYZtix2D4E4TYIUnEHr1aAYfY\nZwFJ2zy1x7GfiOGOsCAU+7zfPFVwYzD8XBC7ndzeBsvVOVfsPT1yR3WIfdaQVMU+NCTn920wtx1i\nnxqmNWU0Tfu2pmm7NE3bqmna/Zqm5czUgY2FiKgYpdi9hqyZK8X+NiD2pCl2kBWLQ+yzhqQSO0h1\nuUDgxIqKURfSiU7swBPAcl3XVwJ7gK9M/5DGh8cjkz3CYz/JyL2fi83T7Gw56cPDbwtVM+eKHcRn\nd4h91pDUzVMQO6anx0rIm2M4Vsz0MK0po+v647quG9TKJqBi+oc0Mfh8UYp91XK5AuztzmcLikl7\ne5Ma7pdUxd7VNemOVQ4mjqTGsYMQe3f33FxPceAQ+/Qwk1/bzcAfZvD9xoQidlOx3/5pOGvN3FwF\nqiywKsqfZMU+Aw2MJg67Ylf/dxT7jCOpmacg5zcQSBqxq7k95xvHcGIQu6ZpTwIlcf50h67rDxrP\nuQMIAr8b431uAW4BWKQaD08DqqynUuzulQ1wSsPYL5opKImcZGJPumKfx/Wq3+5Iusd+7Jj8PBEV\n+wIIdxz3a9N1/eKx/q5p2g3AFcBFuq7rY7zP3cDdAGvWrEn4vInC5xNBEQzKxJ/TkslKsbe3y0/H\nY5/DAzgxkHRib26WnyeSx56aKkRyIij2saBp2gbgS8B5uq4PzswhTQx2j31OTz6c2IpdKbieHofY\nZxFJ2zxVqrXJSPhLshUzp9e2pkUWApvHxD7dKfNjIBN4QtO0LZqm/WwGjmlCsHvsc+rDwdtGsSeF\n2L1eudoGBhxin0UkTbGr9oeqZOaJZMXAgiH2aX1tuq4vnqkDmSwcxZ4kK8auahxinzUkbfNUNSzf\ns0d+nmjEbq/JPo+JfV6WFIBIYk+aYj9+XH4mqUdbUhQ7OMQ+B0iaYvf7hcz37pXfk+SxJ8WKgcjS\nvQ6xzz3sVkxSTj5Yy9Wiojk+AEFSFDs4xD4HSBqxg8xnpVpPNMWu5nYoJOTuEPvcwh7uOOeK3eWS\nCaCIXS1f5xiOYl+4UDdtSAKxFxdb/1er0zlG0oldhfI6xD63SOrmKQibKivmRFPsqma3Q+yzBjuZ\nJ43YMzOTdHElqTUeCLH39TnEniyoOPakbJ6CpWTc7tiGpHOEmho5DBXIMGdQpV2dkgJzgjknNyVU\nkmTDwNvAY3eIPTl4Wyh2EFadc0kleO974ehRK6dkzuBYMXOKpCn2JBJ7eTnceCOcf/4cf/ACIfZ5\nWY8dkhzuCJZiT5K/DhJ5OOekDrGT3yH2WUVSNk8hqcTu8cCvf52ED1ZzWzV7mKfE7ij2qUIp9iT5\n60mFo9jnFHNaLgMsxZ6kUMekIjNT1KKqF+MQ+9zCUexJhEPsc4qkEXsSFXvSoEKZVV9fh9jnFirc\n0VHsSUB6eqSqcYh9YeFtYMUkDQ6xJxc+H4TDQu6OYp9jqMmvGno7xL6w4Cj2pJcLmS7mNbGDRN05\nin2OoSa/6vvqEPvCQmYmfOpTcOWVyT6SuccCUezzOioGhNiTUqrFUewOsS9UaBr88IfJPorkYIEQ\n+7xX7IODjmKfc9iJ3e1Owu6eAwezBIfYkws7sSfFY1+zBpYvh5NOSsKHJxl2YnfU+qzhwguTfQQn\nIBYIsS8IKyYpir2hAbZtS8IHvw1gJ/Z5OvHnAx59VOa3gzmEWok7xJ4cqFoSSVPsJzJUuquj2GcV\nPp8lYBzMEZRoSXJ3tOli3lsxgUDSCtCduLCHOzrE7mAhQTW0PnBAfp+nwRHzntjBIfY5hyJ2cIjd\nwcKCyyUr0kBAqrbOeU3smcGCIHbHiplj2CuPOcTuYKFBCZfKyuQexzSwIIjdUexzDLfbSh5wiN3B\nQoMi9kWLknsc08C0iF3TtK9rmrZV07QtmqY9rmla2Uwd2HhwFHuSoSa/Q+wOFhocxc63dV1fqev6\nKuBh4P/NwDFNCPaekI5iTwJKS+Vnfn5yj8OBg5nGAlDs09K6uq732n5NB/TpHc7E4Sj2JOOJJyRy\noL4+2UfiwMHMQm2YnqjEDqBp2jeA64Ee4IJpH9EEYSf2iy6aq091YKKo6MQsp+Bg4eNEsGI0TXtS\n07Ttcf5dCaDr+h26rlcCvwNuG+N9btE0bbOmaZvb2tqmfeD2wl8f+tC0386BAwcOBCeCFaPr+sUT\nfK//BB4B/inB+9wN3A2wZs2aaVs22dnwq1/BpZc6NagcOHAwg8jIEFIpm7NYkBnHtKwYTdPqdV3f\na/z6LmDX9A9p4rjpprn8NAcOHJwQuOEGqKub1xFf0/XY79Q0bSkQBg4DH5/+ITlw4MBBEnHaafJv\nHmO6UTHvnakDceDAgQMHM4N5m3nqwIEDBw7iwyF2Bw4cOFhgcIjdgQMHDhYYHGJ34MCBgwUGh9gd\nOHDgYIHBIXYHDhw4WGBwiN2BAwcOFhg0XZ+zgozWh2paG5LQNBUUAO0zeDhvZzhjXXg4UcYJzlhn\nA1W6ro/biDUpxD4daJq2Wdf1Nck+jrmAM9aFhxNlnOCMNZlwrBgHDhw4WGBwiN2BAwcOFhjmI7Hf\nnewDmEM4Y114OFHGCc5Yk4Z557E7cODAgYOxMR8VuwMHDhw4GAPzitg1TdugadpuTdP2aZr25WQf\nz0xC07RDmqZt0zRti6Zpm43H8jRNe0LTtL3Gz9xkH+dUoGnarzRNa9U0bbvtsbhj0wQ/NM7xVk3T\nVifvyCePBGP9Z03Tmo1zu0XTtMttf/uKMdbdmqZdlpyjnho0TavUNO0ZTdN2apq2Q9O0zxiPL6hz\nO8Y4377nVdf1efEPcAP7gVrAC7wJnJzs45rB8R0CCqIe+xbwZeP/Xwb+LdnHOcWxnQusBraPNzbg\ncuCvgAasA15O9vHPwFj/Gfh8nOeebMxjH1BjzG93sscwibGWAquN/2cCe4wxLahzO8Y437bndT4p\n9rXAPl3XD+i6PgL8Hrgyycc027gSuNf4/73Au5N4LFOGruvPA51RDyca25XAb3TBJiBH07TSuTnS\n6SPBWBPhSuD3uq4P67p+ENiHzPN5AV3Xj+m6/rrx/z5gJ1DOAju3Y4wzEZJ+XucTsZcDR2y/NzH2\nlzvfoAOPa5r2mqZptxiPFeu6fgxkcgFFSTu6mUeisS3U83ybYT/8ymapLZixappWDZwKvMwCPrdR\n44S36XmdT8SuxXlsIYX0nKXr+mrgHcCtmqadm+wDShIW4nn+KVAHrAKOAd81Hl8QY9U0LQP4M/BZ\nXdd7x3pqnMfmzXjjjPNte17nE7E3AZW23yuAo0k6lhmHrutHjZ+twP3I0q1FLVWNn63JO8IZR6Kx\nLbjzrOt6i67rIV3Xw8DPsZbl836smqalIGT3O13X/2I8vODObbxxvp3P63wi9leBek3TajRN8wLX\nAA8l+ZhmBJqmpWualqn+D1wKbEfGd4PxtBuAB5NzhLOCRGN7CLjeiKBYB/SoZf18RZSPfBVybkHG\neo2maT5N02qAeuCVuT6+qULTNA34JbBT1/Xv2f60oM5tonG+rc9rsnecJ7k7fTmyI70fuCPZxzOD\n46pFdtHfBHaosQH5wFPAXuNnXrKPdYrj+y9kqTqKqJkPJxobsoz9d+McbwPWJPv4Z2Cs9xlj2Ypc\n9KW2599hjHU38I5kH/8kx3o2YjFsBbYY/y5faOd2jHG+bc+rk3nqwIEDBwsM88mKceDAgQMHE4BD\n7A4cOHCwwOAQuwMHDhwsMDjE7sCBAwcLDA6xO3DgwMECg0PsDhw4cLDA4BC7AwcOHCwwOMTuwIED\nBwsM/x/IEqUcV6p1DQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2785195e400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_series(walking[100, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! But now we come to an interesting question... can we, intelligent humans, tell between different people's data by eye?\n",
    "\n",
    "Let's plot a few series for some different people - say, 5 series for 3 people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](three.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't look like this is an easy problem for us to solve, even with our big human brains. Maybe the computer will be able to give us a run for our money...\n",
    "\n",
    "\n",
    "So we have our data; now we need our labels. Each observation comes from one of 15 people so we can quickly check that we have 15 labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walking_labels = np.load(\"data/walking_labels.npy\")\n",
    "set(walking_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time has come to split our data, but we'll have to use a slightly different tactic to the `iris` example earlier, because our labels are already separated.\n",
    "\n",
    "We'll split the row indices into three sets - a 60:20:20 split into training, cross-validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = walking.shape[0]\n",
    "indices = [x for x in range(m)]\n",
    "np.random.shuffle(indices)\n",
    "train_indices = indices[:int(m*0.6)]\n",
    "val_indices = indices[int(m*0.6):int(m*0.8)]\n",
    "test_indices = indices[int(m*0.8):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use these indices to partition both our data and our labels, remembering that we need to one-hot encode the labels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = walking[train_indices, :, :]\n",
    "X_val = walking[val_indices, :, :]\n",
    "X_test = walking[test_indices, :, :]\n",
    "\n",
    "y_train = to_categorical(walking_labels[train_indices])\n",
    "y_val = to_categorical(walking_labels[val_indices])\n",
    "y_test = to_categorical(walking_labels[test_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, to start with, we need a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we're gonna need some more layers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, MaxPooling1D, Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first layer is going to be a **convolutional layer**. Instead of looking at the whole set of features (timesteps) in one go, this layer looks at a moving \"window\" of features, so it's great for identifying patterns which are repeated, or pattern which appear often but in not necessarily in the same place every time.\n",
    "\n",
    "The \"dimensionality\" of the convolutional window depends on how we want to move this window, which depends on our data. Here, we have time series data, which we can move \"along\", forwards and backwards, in _one_ dimension; so we use 1D convolution. If we had images instead, we could move the window in _two_ dimensions (left-right and up-down), so it would make more sense to use 2D convolution.\n",
    "\n",
    "We need to pass some arguments into this convolutional layer:\n",
    "\n",
    "* `filters`: Like `units` in a dense layer - the number of \"features\" we want to learn, or number of patterns to try to identify.\n",
    "* `kernel_size`: The \"window\" we were just talking about is officially called a **kernel**. We use at a rolling window capturing [`kernel_size`] timesteps at once.\n",
    "* `strides`: How many time steps to \"roll forward\" each time we move the window. The larger we set it, the fewer snapshots of our series the kernel will see, so the fewer output neurons will be created.\n",
    "* `activation`: Just like in the dense layer earlier, except convolutional layers typically use the REctified Linear Unit activation function because it works well and is fast to train\n",
    "* `input_shape`: Remember, the first layer always needs an input shape so it knows what data it is expecting! This time, we're feeding in observations each of shape ({260 timesteps}, {3 directional acceleration channels})\n",
    "\n",
    "If we want to get fancy, we can call these arguments **hyperparameters** of our network. The **parameters** are hidden away inside the neurons in each layer, and they get updated during training. The hyperparameters are set by us, and control the shape and behaviour of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv1D(filters=30, kernel_size=40, strides=2, activation=\"relu\", input_shape=(260, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll add a \"subsampling\" layer. This type of layer groups neurons up based on their position, and then combines them, thereby reducing the number of neurons that pass forward into the next layer.\n",
    "\n",
    "This has two main effects:\n",
    "* With fewer neurons, the number of _parameters_ in the following layers of the network is reduced; so there's less updating to be done after each batch, and the network will be less computationally-intensive (i.e. faster!) to train.\n",
    "* We reduce the chances of learning to recognise super-specific features (and then relying on them later on for our classifications), because we're combining bits and pieces from different neurons. This means our network should generalise better to making predictions on data outside our training set.\n",
    "\n",
    "We're using \"max pooling\" as our subsampling tactic, which just takes the strongest neuron from each \"pool\" (i.e. the one with the highest activation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(MaxPooling1D(pool_size=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But... _why_ have we just added a convolutional layer and then a pooling layer? Why didn't we add another convolutional layer first? Why did we pair neurons up, instead of combining 3 at a time?\n",
    "\n",
    "These are all valid questions.\n",
    "\n",
    "The fun, slightly artistic part of building a deep learning model is deciding which layers to add, how big to make them, which hyperparameters to adjust, how to adjust them, when to adjust them, ...\n",
    "\n",
    "There are a few common rules-of-thumb though. The conv-pool combo we've just seen is very common - convolutional layers add a load of new parameters to the model, and then pooling layers (or other subsampling layers, such as \"dropout\") strip the new neurons down and help prevent overfitting.\n",
    "\n",
    "We're going to add another conv-pool pair of layers to our model. The neurons in the first convolutional layer will learn to respond to patterns in our time series data. The neurons in the _second_ convolutional layer will learn to respond to patterns in the (pooled) output of the _first_ layer - so it's responding to _meta-patterns_ in the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Conv1D(filters=30, kernel_size=10, activation=\"relu\"))\n",
    "model.add(MaxPooling1D(pool_size=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pause for a moment and check the shape of the data which is coming out of the last layer of the network right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 23, 30)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice anything?\n",
    "\n",
    "Yeah, it's still in 3D: some number of rows (which Keras represents with `None`, because we could feed in any number of observations!), some \"features\" (loosely related to our original timesteps, but twisted beyond recognition by the conv/pool layers), and some \"filters\" (the number which we set in the latest conv layer).\n",
    "\n",
    "But if we think about what we want to predict... that's in 2D! Some number of rows, where each one is a one-hot label.\n",
    "\n",
    "So we somehow need to _flatten_ our network by taking all those stacked-up parameters and laying them out next to each other in a big long line.\n",
    "\n",
    "This is Keras though, so it's easy to do that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now if we check the shape again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 690)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the same size of output as before, just reshaped!\n",
    "\n",
    "Now we can finish off by feeding this into a couple of dense layers. The first one will learn relationships between the now-flattened convolutional neurons, and the second produces the (one-hot) prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(100, activation=\"sigmoid\"))\n",
    "model.add(Dense(15, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a step back and admire our handiwork."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 111, 30)           3630      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 55, 30)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 46, 30)            9030      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 23, 30)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 690)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               69100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 15)                1515      \n",
      "=================================================================\n",
      "Total params: 83,275\n",
      "Trainable params: 83,275\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We have to compile the network before we can run it, defining:\n",
    "# * Loss function to use (always categorical cross-entropy for multi-class logistic regression)\n",
    "# * Optimizer to use\n",
    "#   (\"adam\" = \"ADAptive Movement estimation\", but e.g. \"sgd\" = \"Stochastic Gradient Descent\" will work, just slower)\n",
    "# * Metrics to report (NOT used for adjusting parameters - that's what the loss function is for!)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit it!\n",
    "# * X_train and y_train are training data/labels\n",
    "# * epochs: How many times to pass the training data through and update the network's parameters\n",
    "# * batch_size: How many observations to include in each batch the optimizer sees\n",
    "# * Also show us the accuracy for the cross-validation set\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=100, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we could try to improve that cross-validation accuracy score, e.g. change network structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_test)\n",
    "print(classification_report(np.argmax(y_test, axis=1), y_pred))\n",
    "print(confusion_matrix(np.argmax(y_test, axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try to visualise the \"features\" of the time series which the convolutional layers of the net have learned to identify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the weights from a given layer\n",
    "def plot_filter(model, layer, k):\n",
    "    x = model.layers[layer].get_weights()[0][:, :, k]\n",
    "    plot_series(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_filter(model, 0, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can also see if there are any patterns in the autocorrelation plots which might suggest strong periodicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_filter_corr(model, layer, k):\n",
    "    weights = model.layers[layer].get_weights()[0][:, :, k]\n",
    "    corrs = np.apply_along_axis(lambda y: np.correlate(y, y, mode=\"full\"), 0, weights)\n",
    "    plot_series(corrs[corrs.shape[0]//2:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_filter_corr(model, 0, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot each filter with its autocorrelation plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=5, nrows=2, figsize=(50, 20))\n",
    "\n",
    "for k in range(5):\n",
    "    plt.subplot(2, 5, 1+k)\n",
    "    plot_filter(model, 0, k)\n",
    "    plt.subplot(2, 5, 6+k)\n",
    "    plot_filter_corr(model, 0, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig.savefig(\"corrs.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
